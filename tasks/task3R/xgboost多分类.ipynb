{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abca84b-c969-490f-99f5-75d49bf56168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"../../tools/\")\n",
    "import commontools\n",
    "import ucTools\n",
    "import funclib\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import joblib  # 将模型导出所需包\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53e8a1d-aff3-43a8-8ef2-e9f4eb85fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather('../../data/benchmark/data/train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdc74947-7e90-42b5-b05a-fb25d7e8ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train.isemzyme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b81915dd-135d-4194-bfbe-baa5bed9c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = train.iloc[0:20000,4:1914]\n",
    "data_y = np.array(train.functionCounts.iloc[0:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79ea4fe5-364a-47ea-bd22-02145e53c751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "764ea65f-033a-47c0-a5ea-91c7811649b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = data_y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e386b48e-7f94-42ea-8cdc-d031719c548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x,data_y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f32d15d-301f-4d00-b03c-a5a0f6fc81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_features_top(model_str, model, x_train):\n",
    "    \"\"\"打印模型的重要指标，排名top50指标\"\"\"\n",
    "    print(\"打印XGBoost重要指标\")\n",
    "    feature_importances_ = model.feature_importances_\n",
    "    feature_names = x_train.columns\n",
    "    importance_col = pd.DataFrame([*zip(feature_names, feature_importances_)],  columns=['features', 'weight'])\n",
    "    importance_col_desc = importance_col.sort_values(by='weight', ascending=False)\n",
    "    print(importance_col_desc.iloc[:50, :])\n",
    "\n",
    "def xgboost_model(data_x,data_y):\n",
    "    \n",
    "    \"\"\"用XGBoost进行建模，返回训练好的模型\"\"\"\n",
    "    x_train, x_vali, y_train, y_vali = train_test_split(data_x,data_y,test_size=0.3,random_state=1)\n",
    "    eval_set = [(x_train, y_train), (x_vali, y_vali)]\n",
    "    \n",
    "    xgboost_clf = XGBClassifier(min_child_weight=6, max_depth=15, objective='multi:softmax', num_class=11, use_label_encoder=False)\n",
    "    print(\"-\" * 100)\n",
    "    print(\"几功能酶xgboost模型：\", xgboost_clf)\n",
    "    xgboost_clf.fit(x_train, y_train, eval_metric=\"mlogloss\", eval_set=eval_set, verbose=True)\n",
    "    # # 打印重要性指数\n",
    "    importance_features_top('xgboost', xgboost_clf, x_train)\n",
    "    # 保存模型\n",
    "    joblib.dump(xgboost_clf, './XGBoost_model_v1.0')\n",
    "    return xgboost_clf\n",
    "\n",
    "def print_precison_recall_f1(y_true, y_pre):\n",
    "    \"\"\"打印精准率、召回率和F1值\"\"\"\n",
    "    print(\"打印精准率、召回率和F1值\")\n",
    "    print(classification_report(y_true, y_pre))\n",
    "    f1 = round(f1_score(y_true, y_pre, average='macro'), 2)\n",
    "    p = round(precision_score(y_true, y_pre, average='macro'), 2)\n",
    "    r = round(recall_score(y_true, y_pre, average='macro'), 2)\n",
    "    print(\"Precision: {}, Recall: {}, F1: {} \".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27bfa444-295f-4e36-b61c-40ba574fbf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "几功能酶xgboost模型： XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=15,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_class=11,\n",
      "              num_parallel_tree=None, objective='multi:softmax',\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "[0]\tvalidation_0-mlogloss:1.16518\tvalidation_1-mlogloss:1.17082\n",
      "[1]\tvalidation_0-mlogloss:0.85412\tvalidation_1-mlogloss:0.87449\n",
      "[2]\tvalidation_0-mlogloss:0.65743\tvalidation_1-mlogloss:0.69237\n",
      "[3]\tvalidation_0-mlogloss:0.51460\tvalidation_1-mlogloss:0.56760\n",
      "[4]\tvalidation_0-mlogloss:0.40968\tvalidation_1-mlogloss:0.47928\n",
      "[5]\tvalidation_0-mlogloss:0.32982\tvalidation_1-mlogloss:0.41727\n",
      "[6]\tvalidation_0-mlogloss:0.26772\tvalidation_1-mlogloss:0.36965\n",
      "[7]\tvalidation_0-mlogloss:0.21831\tvalidation_1-mlogloss:0.33526\n",
      "[8]\tvalidation_0-mlogloss:0.17932\tvalidation_1-mlogloss:0.31046\n",
      "[9]\tvalidation_0-mlogloss:0.14896\tvalidation_1-mlogloss:0.29148\n",
      "[10]\tvalidation_0-mlogloss:0.12450\tvalidation_1-mlogloss:0.27736\n",
      "[11]\tvalidation_0-mlogloss:0.10416\tvalidation_1-mlogloss:0.26737\n",
      "[12]\tvalidation_0-mlogloss:0.08807\tvalidation_1-mlogloss:0.26093\n",
      "[13]\tvalidation_0-mlogloss:0.07528\tvalidation_1-mlogloss:0.25520\n",
      "[14]\tvalidation_0-mlogloss:0.06485\tvalidation_1-mlogloss:0.25099\n",
      "[15]\tvalidation_0-mlogloss:0.05634\tvalidation_1-mlogloss:0.24828\n",
      "[16]\tvalidation_0-mlogloss:0.04935\tvalidation_1-mlogloss:0.24696\n",
      "[17]\tvalidation_0-mlogloss:0.04349\tvalidation_1-mlogloss:0.24562\n",
      "[18]\tvalidation_0-mlogloss:0.03877\tvalidation_1-mlogloss:0.24415\n",
      "[19]\tvalidation_0-mlogloss:0.03493\tvalidation_1-mlogloss:0.24384\n",
      "[20]\tvalidation_0-mlogloss:0.03152\tvalidation_1-mlogloss:0.24381\n",
      "[21]\tvalidation_0-mlogloss:0.02884\tvalidation_1-mlogloss:0.24372\n",
      "[22]\tvalidation_0-mlogloss:0.02637\tvalidation_1-mlogloss:0.24425\n",
      "[23]\tvalidation_0-mlogloss:0.02425\tvalidation_1-mlogloss:0.24507\n",
      "[24]\tvalidation_0-mlogloss:0.02240\tvalidation_1-mlogloss:0.24531\n",
      "[25]\tvalidation_0-mlogloss:0.02077\tvalidation_1-mlogloss:0.24592\n",
      "[26]\tvalidation_0-mlogloss:0.01936\tvalidation_1-mlogloss:0.24667\n",
      "[27]\tvalidation_0-mlogloss:0.01819\tvalidation_1-mlogloss:0.24738\n",
      "[28]\tvalidation_0-mlogloss:0.01715\tvalidation_1-mlogloss:0.24837\n",
      "[29]\tvalidation_0-mlogloss:0.01626\tvalidation_1-mlogloss:0.24889\n",
      "[30]\tvalidation_0-mlogloss:0.01544\tvalidation_1-mlogloss:0.24939\n",
      "[31]\tvalidation_0-mlogloss:0.01465\tvalidation_1-mlogloss:0.25030\n",
      "[32]\tvalidation_0-mlogloss:0.01396\tvalidation_1-mlogloss:0.25130\n",
      "[33]\tvalidation_0-mlogloss:0.01341\tvalidation_1-mlogloss:0.25185\n",
      "[34]\tvalidation_0-mlogloss:0.01289\tvalidation_1-mlogloss:0.25282\n",
      "[35]\tvalidation_0-mlogloss:0.01241\tvalidation_1-mlogloss:0.25409\n",
      "[36]\tvalidation_0-mlogloss:0.01196\tvalidation_1-mlogloss:0.25442\n",
      "[37]\tvalidation_0-mlogloss:0.01157\tvalidation_1-mlogloss:0.25473\n",
      "[38]\tvalidation_0-mlogloss:0.01120\tvalidation_1-mlogloss:0.25520\n",
      "[39]\tvalidation_0-mlogloss:0.01084\tvalidation_1-mlogloss:0.25583\n",
      "[40]\tvalidation_0-mlogloss:0.01053\tvalidation_1-mlogloss:0.25656\n",
      "[41]\tvalidation_0-mlogloss:0.01022\tvalidation_1-mlogloss:0.25697\n",
      "[42]\tvalidation_0-mlogloss:0.00992\tvalidation_1-mlogloss:0.25783\n",
      "[43]\tvalidation_0-mlogloss:0.00968\tvalidation_1-mlogloss:0.25866\n",
      "[44]\tvalidation_0-mlogloss:0.00941\tvalidation_1-mlogloss:0.25927\n",
      "[45]\tvalidation_0-mlogloss:0.00917\tvalidation_1-mlogloss:0.26011\n",
      "[46]\tvalidation_0-mlogloss:0.00895\tvalidation_1-mlogloss:0.26092\n",
      "[47]\tvalidation_0-mlogloss:0.00872\tvalidation_1-mlogloss:0.26175\n",
      "[48]\tvalidation_0-mlogloss:0.00852\tvalidation_1-mlogloss:0.26200\n",
      "[49]\tvalidation_0-mlogloss:0.00832\tvalidation_1-mlogloss:0.26262\n",
      "[50]\tvalidation_0-mlogloss:0.00814\tvalidation_1-mlogloss:0.26316\n",
      "[51]\tvalidation_0-mlogloss:0.00797\tvalidation_1-mlogloss:0.26357\n",
      "[52]\tvalidation_0-mlogloss:0.00780\tvalidation_1-mlogloss:0.26397\n",
      "[53]\tvalidation_0-mlogloss:0.00765\tvalidation_1-mlogloss:0.26421\n",
      "[54]\tvalidation_0-mlogloss:0.00750\tvalidation_1-mlogloss:0.26484\n",
      "[55]\tvalidation_0-mlogloss:0.00736\tvalidation_1-mlogloss:0.26510\n",
      "[56]\tvalidation_0-mlogloss:0.00722\tvalidation_1-mlogloss:0.26535\n",
      "[57]\tvalidation_0-mlogloss:0.00710\tvalidation_1-mlogloss:0.26554\n",
      "[58]\tvalidation_0-mlogloss:0.00698\tvalidation_1-mlogloss:0.26545\n",
      "[59]\tvalidation_0-mlogloss:0.00686\tvalidation_1-mlogloss:0.26618\n",
      "[60]\tvalidation_0-mlogloss:0.00675\tvalidation_1-mlogloss:0.26663\n",
      "[61]\tvalidation_0-mlogloss:0.00664\tvalidation_1-mlogloss:0.26702\n",
      "[62]\tvalidation_0-mlogloss:0.00653\tvalidation_1-mlogloss:0.26758\n",
      "[63]\tvalidation_0-mlogloss:0.00643\tvalidation_1-mlogloss:0.26837\n",
      "[64]\tvalidation_0-mlogloss:0.00634\tvalidation_1-mlogloss:0.26856\n",
      "[65]\tvalidation_0-mlogloss:0.00624\tvalidation_1-mlogloss:0.26900\n",
      "[66]\tvalidation_0-mlogloss:0.00616\tvalidation_1-mlogloss:0.26906\n",
      "[67]\tvalidation_0-mlogloss:0.00607\tvalidation_1-mlogloss:0.26912\n",
      "[68]\tvalidation_0-mlogloss:0.00600\tvalidation_1-mlogloss:0.26965\n",
      "[69]\tvalidation_0-mlogloss:0.00592\tvalidation_1-mlogloss:0.27019\n",
      "[70]\tvalidation_0-mlogloss:0.00584\tvalidation_1-mlogloss:0.27056\n",
      "[71]\tvalidation_0-mlogloss:0.00577\tvalidation_1-mlogloss:0.27114\n",
      "[72]\tvalidation_0-mlogloss:0.00570\tvalidation_1-mlogloss:0.27148\n",
      "[73]\tvalidation_0-mlogloss:0.00563\tvalidation_1-mlogloss:0.27190\n",
      "[74]\tvalidation_0-mlogloss:0.00557\tvalidation_1-mlogloss:0.27207\n",
      "[75]\tvalidation_0-mlogloss:0.00550\tvalidation_1-mlogloss:0.27246\n",
      "[76]\tvalidation_0-mlogloss:0.00544\tvalidation_1-mlogloss:0.27249\n",
      "[77]\tvalidation_0-mlogloss:0.00538\tvalidation_1-mlogloss:0.27266\n",
      "[78]\tvalidation_0-mlogloss:0.00532\tvalidation_1-mlogloss:0.27292\n",
      "[79]\tvalidation_0-mlogloss:0.00527\tvalidation_1-mlogloss:0.27312\n",
      "[80]\tvalidation_0-mlogloss:0.00521\tvalidation_1-mlogloss:0.27326\n",
      "[81]\tvalidation_0-mlogloss:0.00516\tvalidation_1-mlogloss:0.27353\n",
      "[82]\tvalidation_0-mlogloss:0.00511\tvalidation_1-mlogloss:0.27383\n",
      "[83]\tvalidation_0-mlogloss:0.00506\tvalidation_1-mlogloss:0.27409\n",
      "[84]\tvalidation_0-mlogloss:0.00500\tvalidation_1-mlogloss:0.27440\n",
      "[85]\tvalidation_0-mlogloss:0.00495\tvalidation_1-mlogloss:0.27438\n",
      "[86]\tvalidation_0-mlogloss:0.00491\tvalidation_1-mlogloss:0.27463\n",
      "[87]\tvalidation_0-mlogloss:0.00487\tvalidation_1-mlogloss:0.27479\n",
      "[88]\tvalidation_0-mlogloss:0.00482\tvalidation_1-mlogloss:0.27523\n",
      "[89]\tvalidation_0-mlogloss:0.00477\tvalidation_1-mlogloss:0.27558\n",
      "[90]\tvalidation_0-mlogloss:0.00473\tvalidation_1-mlogloss:0.27583\n",
      "[91]\tvalidation_0-mlogloss:0.00468\tvalidation_1-mlogloss:0.27591\n",
      "[92]\tvalidation_0-mlogloss:0.00464\tvalidation_1-mlogloss:0.27616\n",
      "[93]\tvalidation_0-mlogloss:0.00460\tvalidation_1-mlogloss:0.27634\n",
      "[94]\tvalidation_0-mlogloss:0.00456\tvalidation_1-mlogloss:0.27660\n",
      "[95]\tvalidation_0-mlogloss:0.00453\tvalidation_1-mlogloss:0.27688\n",
      "[96]\tvalidation_0-mlogloss:0.00449\tvalidation_1-mlogloss:0.27752\n",
      "[97]\tvalidation_0-mlogloss:0.00446\tvalidation_1-mlogloss:0.27769\n",
      "[98]\tvalidation_0-mlogloss:0.00442\tvalidation_1-mlogloss:0.27789\n",
      "[99]\tvalidation_0-mlogloss:0.00439\tvalidation_1-mlogloss:0.27818\n",
      "打印XGBoost重要指标\n",
      "     features    weight\n",
      "1700    f1701  0.008035\n",
      "703      f704  0.007959\n",
      "1510    f1511  0.006522\n",
      "715      f716  0.006396\n",
      "644      f645  0.006266\n",
      "1307    f1308  0.005025\n",
      "1250    f1251  0.004699\n",
      "1803    f1804  0.004128\n",
      "1457    f1458  0.003993\n",
      "826      f827  0.003818\n",
      "1682    f1683  0.003786\n",
      "1116    f1117  0.003598\n",
      "1412    f1413  0.003450\n",
      "1652    f1653  0.003247\n",
      "171      f172  0.003094\n",
      "1223    f1224  0.003043\n",
      "1286    f1287  0.003023\n",
      "869      f870  0.002990\n",
      "46        f47  0.002974\n",
      "463      f464  0.002974\n",
      "827      f828  0.002810\n",
      "91        f92  0.002798\n",
      "1601    f1602  0.002775\n",
      "364      f365  0.002746\n",
      "1325    f1326  0.002676\n",
      "1408    f1409  0.002616\n",
      "209      f210  0.002589\n",
      "1856    f1857  0.002578\n",
      "693      f694  0.002534\n",
      "355      f356  0.002498\n",
      "1855    f1856  0.002440\n",
      "1436    f1437  0.002350\n",
      "1639    f1640  0.002336\n",
      "781      f782  0.002300\n",
      "1491    f1492  0.002287\n",
      "1172    f1173  0.002260\n",
      "1458    f1459  0.002238\n",
      "464      f465  0.002220\n",
      "812      f813  0.002212\n",
      "1072    f1073  0.002202\n",
      "506      f507  0.002190\n",
      "1097    f1098  0.002173\n",
      "923      f924  0.002109\n",
      "1695    f1696  0.002104\n",
      "1837    f1838  0.002097\n",
      "415      f416  0.002096\n",
      "265      f266  0.002067\n",
      "1261    f1262  0.002049\n",
      "215      f216  0.002018\n",
      "1818    f1819  0.002013\n"
     ]
    }
   ],
   "source": [
    "xgboost_clf = xgboost_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f510779f-fce7-47d4-bfea-4d97cefea977",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_train, y_train), (x_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37bcbafa-f9f6-46ad-9516-c1ba6ade46ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xost_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-6f9f5eb4f3f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxost_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xost_clf' is not defined"
     ]
    }
   ],
   "source": [
    "pre_y_test = xgbost_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08646516-661e-4491-ada4-5544c6729b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f1891</th>\n",
       "      <th>f1892</th>\n",
       "      <th>f1893</th>\n",
       "      <th>f1894</th>\n",
       "      <th>f1895</th>\n",
       "      <th>f1896</th>\n",
       "      <th>f1897</th>\n",
       "      <th>f1898</th>\n",
       "      <th>f1899</th>\n",
       "      <th>f1900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.004133</td>\n",
       "      <td>0.031950</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.084028</td>\n",
       "      <td>-0.106755</td>\n",
       "      <td>-0.198294</td>\n",
       "      <td>-0.000912</td>\n",
       "      <td>0.010045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.064062</td>\n",
       "      <td>0.084055</td>\n",
       "      <td>-0.039602</td>\n",
       "      <td>-0.011034</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>0.153470</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.032580</td>\n",
       "      <td>-0.034380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.234055</td>\n",
       "      <td>0.202590</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>0.257440</td>\n",
       "      <td>-0.008591</td>\n",
       "      <td>-0.039887</td>\n",
       "      <td>-0.009504</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.014996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198902</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>-0.186542</td>\n",
       "      <td>0.023011</td>\n",
       "      <td>-0.113903</td>\n",
       "      <td>-0.074157</td>\n",
       "      <td>0.820054</td>\n",
       "      <td>0.045937</td>\n",
       "      <td>-0.036160</td>\n",
       "      <td>-0.028256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.292311</td>\n",
       "      <td>0.244053</td>\n",
       "      <td>-0.009429</td>\n",
       "      <td>0.271757</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>-0.078286</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>-0.006165</td>\n",
       "      <td>-0.020575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175442</td>\n",
       "      <td>0.065406</td>\n",
       "      <td>-0.041244</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>-0.079137</td>\n",
       "      <td>0.789780</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>-0.033467</td>\n",
       "      <td>-0.100108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.245537</td>\n",
       "      <td>0.244524</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>0.386281</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>0.058923</td>\n",
       "      <td>-0.005218</td>\n",
       "      <td>-0.005565</td>\n",
       "      <td>-0.034299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157748</td>\n",
       "      <td>0.305814</td>\n",
       "      <td>-0.130900</td>\n",
       "      <td>0.045086</td>\n",
       "      <td>-0.247851</td>\n",
       "      <td>-0.131615</td>\n",
       "      <td>0.759615</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>-0.045659</td>\n",
       "      <td>-0.123342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003292</td>\n",
       "      <td>-0.010891</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>-0.004417</td>\n",
       "      <td>-0.259515</td>\n",
       "      <td>0.133029</td>\n",
       "      <td>-0.464210</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>-0.005446</td>\n",
       "      <td>0.249855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055954</td>\n",
       "      <td>-0.187867</td>\n",
       "      <td>0.014005</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.390966</td>\n",
       "      <td>-0.139071</td>\n",
       "      <td>-0.140427</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>-0.071718</td>\n",
       "      <td>-0.002881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.070719</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>0.881442</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>-0.002443</td>\n",
       "      <td>-0.001216</td>\n",
       "      <td>-0.625112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>-0.253492</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>-0.471886</td>\n",
       "      <td>-0.143367</td>\n",
       "      <td>-0.066733</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.118797</td>\n",
       "      <td>-0.020916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.071596</td>\n",
       "      <td>0.039163</td>\n",
       "      <td>-0.007932</td>\n",
       "      <td>0.684397</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>-0.005130</td>\n",
       "      <td>-0.003821</td>\n",
       "      <td>-0.699007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.040557</td>\n",
       "      <td>-0.309668</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>-0.497647</td>\n",
       "      <td>-0.113421</td>\n",
       "      <td>-0.026370</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>-0.042494</td>\n",
       "      <td>-0.091926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.064161</td>\n",
       "      <td>-0.001923</td>\n",
       "      <td>0.894576</td>\n",
       "      <td>-0.005141</td>\n",
       "      <td>-0.034928</td>\n",
       "      <td>-0.004715</td>\n",
       "      <td>-0.003473</td>\n",
       "      <td>-0.648881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009807</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>-0.186568</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>-0.702187</td>\n",
       "      <td>-0.083997</td>\n",
       "      <td>-0.046591</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.052006</td>\n",
       "      <td>-0.054832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.001743</td>\n",
       "      <td>-0.010931</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>0.355944</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>-0.081538</td>\n",
       "      <td>-0.007427</td>\n",
       "      <td>-0.001497</td>\n",
       "      <td>-0.138363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>-0.314343</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>-0.466908</td>\n",
       "      <td>-0.089873</td>\n",
       "      <td>-0.013782</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>0.118699</td>\n",
       "      <td>-0.021342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.109819</td>\n",
       "      <td>0.036686</td>\n",
       "      <td>-0.002889</td>\n",
       "      <td>0.819848</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.037715</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>-0.002534</td>\n",
       "      <td>-0.692687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.027521</td>\n",
       "      <td>-0.305679</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>-0.323283</td>\n",
       "      <td>-0.034847</td>\n",
       "      <td>-0.026424</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.095489</td>\n",
       "      <td>-0.063620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0   0.000033 -0.004133  0.031950 -0.000895  0.015118  0.084028 -0.106755   \n",
       "1   0.000181  0.234055  0.202590 -0.009154  0.257440 -0.008591 -0.039887   \n",
       "2   0.000188  0.292311  0.244053 -0.009429  0.271757 -0.005266 -0.078286   \n",
       "3   0.000223  0.245537  0.244524 -0.006509  0.386281  0.054393  0.058923   \n",
       "4   0.003292 -0.010891  0.011057 -0.004417 -0.259515  0.133029 -0.464210   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.000804  0.070719  0.018773 -0.004329  0.881442 -0.000350  0.029116   \n",
       "96  0.002619  0.071596  0.039163 -0.007932  0.684397  0.001810  0.004194   \n",
       "97  0.003020  0.029630  0.064161 -0.001923  0.894576 -0.005141 -0.034928   \n",
       "98  0.001743 -0.010931  0.036082 -0.004149  0.355944  0.046004 -0.081538   \n",
       "99  0.002080  0.109819  0.036686 -0.002889  0.819848 -0.000923  0.037715   \n",
       "\n",
       "          f8        f9       f10  ...     f1891     f1892     f1893     f1894  \\\n",
       "0  -0.198294 -0.000912  0.010045  ... -0.001402 -0.064062  0.084055 -0.039602   \n",
       "1  -0.009504 -0.005681 -0.014996  ...  0.198902 -0.006073 -0.186542  0.023011   \n",
       "2  -0.007095 -0.006165 -0.020575  ...  0.175442  0.065406 -0.041244  0.025119   \n",
       "3  -0.005218 -0.005565 -0.034299  ...  0.157748  0.305814 -0.130900  0.045086   \n",
       "4  -0.002968 -0.005446  0.249855  ...  0.055954 -0.187867  0.014005  0.038685   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95 -0.002443 -0.001216 -0.625112  ...  0.003353  0.010496 -0.253492  0.009834   \n",
       "96 -0.005130 -0.003821 -0.699007  ...  0.002460  0.040557 -0.309668  0.009582   \n",
       "97 -0.004715 -0.003473 -0.648881  ... -0.009807  0.017115 -0.186568  0.011872   \n",
       "98 -0.007427 -0.001497 -0.138363  ...  0.006606  0.081028 -0.314343  0.006154   \n",
       "99 -0.001972 -0.002534 -0.692687  ...  0.010687  0.027521 -0.305679  0.004627   \n",
       "\n",
       "       f1895     f1896     f1897     f1898     f1899     f1900  \n",
       "0  -0.011034 -0.902350  0.153470  0.003805  0.032580 -0.034380  \n",
       "1  -0.113903 -0.074157  0.820054  0.045937 -0.036160 -0.028256  \n",
       "2  -0.096559 -0.079137  0.789780  0.064275 -0.033467 -0.100108  \n",
       "3  -0.247851 -0.131615  0.759615  0.015326 -0.045659 -0.123342  \n",
       "4   0.390966 -0.139071 -0.140427 -0.000358 -0.071718 -0.002881  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95 -0.471886 -0.143367 -0.066733  0.002626 -0.118797 -0.020916  \n",
       "96 -0.497647 -0.113421 -0.026370  0.001468 -0.042494 -0.091926  \n",
       "97 -0.702187 -0.083997 -0.046591  0.002655 -0.052006 -0.054832  \n",
       "98 -0.466908 -0.089873 -0.013782  0.005637  0.118699 -0.021342  \n",
       "99 -0.323283 -0.034847 -0.026424  0.001977 -0.095489 -0.063620  \n",
       "\n",
       "[100 rows x 1900 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b232fc1-e7ee-4bbb-9c57-c00e2e5c0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ 测试集 ------------------------------\n",
      "打印精准率、召回率和F1值\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      3698\n",
      "           0       0.05      0.85      0.09       214\n",
      "           1       0.00      0.00      0.00        36\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.00      0.00      0.00        13\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.05      4000\n",
      "   macro avg       0.00      0.08      0.01      4000\n",
      "weighted avg       0.00      0.05      0.00      4000\n",
      "\n",
      "Precision: 0.0, Recall: 0.08, F1: 0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pre_y_test = xgboost_clf.predict(x_test)\n",
    "# 打印测试集的结果信息，包含precision、recall、f1-socre\n",
    "print(\"-\" * 30, \"测试集\", \"-\" * 30)\n",
    "print_precison_recall_f1((y_test-1), pre_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53002209-4c38-4ffb-8624-0d0c11fc05d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4de7115-d5ff-4f7f-9530-3eef8717e23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>isemzyme</th>\n",
       "      <th>functionCounts</th>\n",
       "      <th>ec_number</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>...</th>\n",
       "      <th>f1891</th>\n",
       "      <th>f1892</th>\n",
       "      <th>f1893</th>\n",
       "      <th>f1894</th>\n",
       "      <th>f1895</th>\n",
       "      <th>f1896</th>\n",
       "      <th>f1897</th>\n",
       "      <th>f1898</th>\n",
       "      <th>f1899</th>\n",
       "      <th>f1900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q3J1A3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.004133</td>\n",
       "      <td>0.031950</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.084028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.064062</td>\n",
       "      <td>0.084055</td>\n",
       "      <td>-0.039602</td>\n",
       "      <td>-0.011034</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>0.153470</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.032580</td>\n",
       "      <td>-0.034380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P02157</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.234055</td>\n",
       "      <td>0.202590</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>0.257440</td>\n",
       "      <td>-0.008591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198902</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>-0.186542</td>\n",
       "      <td>0.023011</td>\n",
       "      <td>-0.113903</td>\n",
       "      <td>-0.074157</td>\n",
       "      <td>0.820054</td>\n",
       "      <td>0.045937</td>\n",
       "      <td>-0.036160</td>\n",
       "      <td>-0.028256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P02178</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.292311</td>\n",
       "      <td>0.244053</td>\n",
       "      <td>-0.009429</td>\n",
       "      <td>0.271757</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175442</td>\n",
       "      <td>0.065406</td>\n",
       "      <td>-0.041244</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>-0.079137</td>\n",
       "      <td>0.789780</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>-0.033467</td>\n",
       "      <td>-0.100108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P02194</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.245537</td>\n",
       "      <td>0.244524</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>0.386281</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157748</td>\n",
       "      <td>0.305814</td>\n",
       "      <td>-0.130900</td>\n",
       "      <td>0.045086</td>\n",
       "      <td>-0.247851</td>\n",
       "      <td>-0.131615</td>\n",
       "      <td>0.759615</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>-0.045659</td>\n",
       "      <td>-0.123342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P01915</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.003292</td>\n",
       "      <td>-0.010891</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>-0.004417</td>\n",
       "      <td>-0.259515</td>\n",
       "      <td>0.133029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055954</td>\n",
       "      <td>-0.187867</td>\n",
       "      <td>0.014005</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.390966</td>\n",
       "      <td>-0.139071</td>\n",
       "      <td>-0.140427</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>-0.071718</td>\n",
       "      <td>-0.002881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469124</th>\n",
       "      <td>Q21221</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1.2.22</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>-0.003616</td>\n",
       "      <td>-0.278141</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>-0.012228</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>-0.044615</td>\n",
       "      <td>-0.042643</td>\n",
       "      <td>-0.249742</td>\n",
       "      <td>0.020233</td>\n",
       "      <td>0.641517</td>\n",
       "      <td>0.263549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469125</th>\n",
       "      <td>Q6QJ72</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2.1.96</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>-0.032054</td>\n",
       "      <td>0.103771</td>\n",
       "      <td>-0.002852</td>\n",
       "      <td>-0.220213</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>-0.003241</td>\n",
       "      <td>-0.006267</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>-0.093495</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.062232</td>\n",
       "      <td>-0.071097</td>\n",
       "      <td>-0.014712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469126</th>\n",
       "      <td>C0HL68</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.467783</td>\n",
       "      <td>0.051187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.052802</td>\n",
       "      <td>-0.013965</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>-0.057094</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>-0.027215</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.131791</td>\n",
       "      <td>0.013848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469127</th>\n",
       "      <td>C0HK74</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-0.407768</td>\n",
       "      <td>0.222164</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>-0.185430</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019540</td>\n",
       "      <td>-0.180971</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>-0.015825</td>\n",
       "      <td>-0.412329</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>-0.006674</td>\n",
       "      <td>-0.028754</td>\n",
       "      <td>0.520137</td>\n",
       "      <td>0.061289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469128</th>\n",
       "      <td>D9XDR8</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2.3.162</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.084315</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>-0.041646</td>\n",
       "      <td>0.726810</td>\n",
       "      <td>0.062709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>-0.108519</td>\n",
       "      <td>-0.128328</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>-0.132280</td>\n",
       "      <td>-0.491997</td>\n",
       "      <td>0.336399</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.107612</td>\n",
       "      <td>-0.022379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469129 rows × 1904 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  isemzyme  functionCounts  ec_number        f1        f2  \\\n",
       "0       Q3J1A3     False               0          -  0.000033 -0.004133   \n",
       "1       P02157     False               0          -  0.000181  0.234055   \n",
       "2       P02178     False               0          -  0.000188  0.292311   \n",
       "3       P02194     False               0          -  0.000223  0.245537   \n",
       "4       P01915     False               0          -  0.003292 -0.010891   \n",
       "...        ...       ...             ...        ...       ...       ...   \n",
       "469124  Q21221      True               1   3.1.2.22  0.002614  0.008250   \n",
       "469125  Q6QJ72      True               1   4.2.1.96  0.002092 -0.032054   \n",
       "469126  C0HL68     False               0          -  0.006038  0.002328   \n",
       "469127  C0HK74     False               0          -  0.000186 -0.407768   \n",
       "469128  D9XDR8      True               1  4.2.3.162  0.000831  0.084315   \n",
       "\n",
       "              f3        f4        f5        f6  ...     f1891     f1892  \\\n",
       "0       0.031950 -0.000895  0.015118  0.084028  ... -0.001402 -0.064062   \n",
       "1       0.202590 -0.009154  0.257440 -0.008591  ...  0.198902 -0.006073   \n",
       "2       0.244053 -0.009429  0.271757 -0.005266  ...  0.175442  0.065406   \n",
       "3       0.244524 -0.006509  0.386281  0.054393  ...  0.157748  0.305814   \n",
       "4       0.011057 -0.004417 -0.259515  0.133029  ...  0.055954 -0.187867   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "469124  0.012764 -0.003616 -0.278141  0.001186  ...  0.008685  0.003675   \n",
       "469125  0.103771 -0.002852 -0.220213 -0.000979  ...  0.015092 -0.003241   \n",
       "469126  0.014656 -0.013047 -0.467783  0.051187  ...  0.019333  0.052802   \n",
       "469127  0.222164 -0.003630 -0.185430 -0.000337  ... -0.019540 -0.180971   \n",
       "469128  0.010529 -0.041646  0.726810  0.062709  ...  0.020245 -0.108519   \n",
       "\n",
       "           f1893     f1894     f1895     f1896     f1897     f1898     f1899  \\\n",
       "0       0.084055 -0.039602 -0.011034 -0.902350  0.153470  0.003805  0.032580   \n",
       "1      -0.186542  0.023011 -0.113903 -0.074157  0.820054  0.045937 -0.036160   \n",
       "2      -0.041244  0.025119 -0.096559 -0.079137  0.789780  0.064275 -0.033467   \n",
       "3      -0.130900  0.045086 -0.247851 -0.131615  0.759615  0.015326 -0.045659   \n",
       "4       0.014005  0.038685  0.390966 -0.139071 -0.140427 -0.000358 -0.071718   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "469124 -0.012228  0.020928 -0.044615 -0.042643 -0.249742  0.020233  0.641517   \n",
       "469125 -0.006267  0.000826 -0.093495  0.007750  0.003061  0.062232 -0.071097   \n",
       "469126 -0.013965  0.016667 -0.057094 -0.001337 -0.027215  0.009131  0.131791   \n",
       "469127  0.005692 -0.015825 -0.412329  0.018995 -0.006674 -0.028754  0.520137   \n",
       "469128 -0.128328  0.048660 -0.132280 -0.491997  0.336399  0.003448  0.107612   \n",
       "\n",
       "           f1900  \n",
       "0      -0.034380  \n",
       "1      -0.028256  \n",
       "2      -0.100108  \n",
       "3      -0.123342  \n",
       "4      -0.002881  \n",
       "...          ...  \n",
       "469124  0.263549  \n",
       "469125 -0.014712  \n",
       "469126  0.013848  \n",
       "469127  0.061289  \n",
       "469128 -0.022379  \n",
       "\n",
       "[469129 rows x 1904 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
