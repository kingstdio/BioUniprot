{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abca84b-c969-490f-99f5-75d49bf56168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"../../tools/\")\n",
    "import commontools\n",
    "import ucTools\n",
    "import funclib\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import joblib  # 将模型导出所需包\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53e8a1d-aff3-43a8-8ef2-e9f4eb85fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather('../../data/benchmark/data/train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdc74947-7e90-42b5-b05a-fb25d7e8ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train.isemzyme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b81915dd-135d-4194-bfbe-baa5bed9c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = train.iloc[0:20000,4:1914]\n",
    "data_y = np.array(train.functionCounts.iloc[0:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79ea4fe5-364a-47ea-bd22-02145e53c751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "764ea65f-033a-47c0-a5ea-91c7811649b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = data_y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e386b48e-7f94-42ea-8cdc-d031719c548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x,data_y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f32d15d-301f-4d00-b03c-a5a0f6fc81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_features_top(model_str, model, x_train):\n",
    "    \"\"\"打印模型的重要指标，排名top50指标\"\"\"\n",
    "    print(\"打印XGBoost重要指标\")\n",
    "    feature_importances_ = model.feature_importances_\n",
    "    feature_names = x_train.columns\n",
    "    importance_col = pd.DataFrame([*zip(feature_names, feature_importances_)],  columns=['features', 'weight'])\n",
    "    importance_col_desc = importance_col.sort_values(by='weight', ascending=False)\n",
    "    print(importance_col_desc.iloc[:50, :])\n",
    "\n",
    "def xgboost_model(data_x,data_y):\n",
    "    \n",
    "    \"\"\"用XGBoost进行建模，返回训练好的模型\"\"\"\n",
    "    x_train, x_vali, y_train, y_vali = train_test_split(data_x,data_y,test_size=0.3,random_state=1)\n",
    "    eval_set = [(x_train, y_train), (x_vali, y_vali)]\n",
    "    \n",
    "    xgboost_clf = XGBClassifier(min_child_weight=6, max_depth=15, objective='multi:softmax', num_class=11, use_label_encoder=False)\n",
    "    print(\"-\" * 100)\n",
    "    print(\"几功能酶xgboost模型：\", xgboost_clf)\n",
    "    xgboost_clf.fit(x_train, y_train, eval_metric=\"mlogloss\", eval_set=eval_set, verbose=True)\n",
    "    # # 打印重要性指数\n",
    "    importance_features_top('xgboost', xgboost_clf, x_train)\n",
    "    # 保存模型\n",
    "    joblib.dump(xgboost_clf, './XGBoost_model_v1.0')\n",
    "    return xgboost_clf\n",
    "\n",
    "def print_precison_recall_f1(y_true, y_pre):\n",
    "    \"\"\"打印精准率、召回率和F1值\"\"\"\n",
    "    print(\"打印精准率、召回率和F1值\")\n",
    "    print(classification_report(y_true, y_pre))\n",
    "    f1 = round(f1_score(y_true, y_pre, average='macro'), 2)\n",
    "    p = round(precision_score(y_true, y_pre, average='macro'), 2)\n",
    "    r = round(recall_score(y_true, y_pre, average='macro'), 2)\n",
    "    print(\"Precision: {}, Recall: {}, F1: {} \".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27bfa444-295f-4e36-b61c-40ba574fbf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "几功能酶xgboost模型： XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=15,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_class=11,\n",
      "              num_parallel_tree=None, objective='multi:softmax',\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "[0]\tvalidation_0-mlogloss:1.16518\tvalidation_1-mlogloss:1.17082\n",
      "[1]\tvalidation_0-mlogloss:0.85412\tvalidation_1-mlogloss:0.87449\n",
      "[2]\tvalidation_0-mlogloss:0.65743\tvalidation_1-mlogloss:0.69237\n",
      "[3]\tvalidation_0-mlogloss:0.51460\tvalidation_1-mlogloss:0.56760\n",
      "[4]\tvalidation_0-mlogloss:0.40968\tvalidation_1-mlogloss:0.47928\n",
      "[5]\tvalidation_0-mlogloss:0.32982\tvalidation_1-mlogloss:0.41727\n",
      "[6]\tvalidation_0-mlogloss:0.26772\tvalidation_1-mlogloss:0.36965\n",
      "[7]\tvalidation_0-mlogloss:0.21831\tvalidation_1-mlogloss:0.33526\n",
      "[8]\tvalidation_0-mlogloss:0.17932\tvalidation_1-mlogloss:0.31046\n",
      "[9]\tvalidation_0-mlogloss:0.14896\tvalidation_1-mlogloss:0.29148\n",
      "[10]\tvalidation_0-mlogloss:0.12450\tvalidation_1-mlogloss:0.27736\n",
      "[11]\tvalidation_0-mlogloss:0.10416\tvalidation_1-mlogloss:0.26737\n",
      "[12]\tvalidation_0-mlogloss:0.08807\tvalidation_1-mlogloss:0.26093\n",
      "[13]\tvalidation_0-mlogloss:0.07528\tvalidation_1-mlogloss:0.25520\n",
      "[14]\tvalidation_0-mlogloss:0.06485\tvalidation_1-mlogloss:0.25099\n",
      "[15]\tvalidation_0-mlogloss:0.05634\tvalidation_1-mlogloss:0.24828\n",
      "[16]\tvalidation_0-mlogloss:0.04935\tvalidation_1-mlogloss:0.24696\n",
      "[17]\tvalidation_0-mlogloss:0.04349\tvalidation_1-mlogloss:0.24562\n",
      "[18]\tvalidation_0-mlogloss:0.03877\tvalidation_1-mlogloss:0.24415\n",
      "[19]\tvalidation_0-mlogloss:0.03493\tvalidation_1-mlogloss:0.24384\n",
      "[20]\tvalidation_0-mlogloss:0.03152\tvalidation_1-mlogloss:0.24381\n",
      "[21]\tvalidation_0-mlogloss:0.02884\tvalidation_1-mlogloss:0.24372\n",
      "[22]\tvalidation_0-mlogloss:0.02637\tvalidation_1-mlogloss:0.24425\n",
      "[23]\tvalidation_0-mlogloss:0.02425\tvalidation_1-mlogloss:0.24507\n",
      "[24]\tvalidation_0-mlogloss:0.02240\tvalidation_1-mlogloss:0.24531\n",
      "[25]\tvalidation_0-mlogloss:0.02077\tvalidation_1-mlogloss:0.24592\n",
      "[26]\tvalidation_0-mlogloss:0.01936\tvalidation_1-mlogloss:0.24667\n",
      "[27]\tvalidation_0-mlogloss:0.01819\tvalidation_1-mlogloss:0.24738\n",
      "[28]\tvalidation_0-mlogloss:0.01715\tvalidation_1-mlogloss:0.24837\n",
      "[29]\tvalidation_0-mlogloss:0.01626\tvalidation_1-mlogloss:0.24889\n",
      "[30]\tvalidation_0-mlogloss:0.01544\tvalidation_1-mlogloss:0.24939\n",
      "[31]\tvalidation_0-mlogloss:0.01465\tvalidation_1-mlogloss:0.25030\n",
      "[32]\tvalidation_0-mlogloss:0.01396\tvalidation_1-mlogloss:0.25130\n",
      "[33]\tvalidation_0-mlogloss:0.01341\tvalidation_1-mlogloss:0.25185\n",
      "[34]\tvalidation_0-mlogloss:0.01289\tvalidation_1-mlogloss:0.25282\n",
      "[35]\tvalidation_0-mlogloss:0.01241\tvalidation_1-mlogloss:0.25409\n",
      "[36]\tvalidation_0-mlogloss:0.01196\tvalidation_1-mlogloss:0.25442\n",
      "[37]\tvalidation_0-mlogloss:0.01157\tvalidation_1-mlogloss:0.25473\n",
      "[38]\tvalidation_0-mlogloss:0.01120\tvalidation_1-mlogloss:0.25520\n",
      "[39]\tvalidation_0-mlogloss:0.01084\tvalidation_1-mlogloss:0.25583\n",
      "[40]\tvalidation_0-mlogloss:0.01053\tvalidation_1-mlogloss:0.25656\n",
      "[41]\tvalidation_0-mlogloss:0.01022\tvalidation_1-mlogloss:0.25697\n",
      "[42]\tvalidation_0-mlogloss:0.00992\tvalidation_1-mlogloss:0.25783\n",
      "[43]\tvalidation_0-mlogloss:0.00968\tvalidation_1-mlogloss:0.25866\n",
      "[44]\tvalidation_0-mlogloss:0.00941\tvalidation_1-mlogloss:0.25927\n",
      "[45]\tvalidation_0-mlogloss:0.00917\tvalidation_1-mlogloss:0.26011\n",
      "[46]\tvalidation_0-mlogloss:0.00895\tvalidation_1-mlogloss:0.26092\n",
      "[47]\tvalidation_0-mlogloss:0.00872\tvalidation_1-mlogloss:0.26175\n",
      "[48]\tvalidation_0-mlogloss:0.00852\tvalidation_1-mlogloss:0.26200\n",
      "[49]\tvalidation_0-mlogloss:0.00832\tvalidation_1-mlogloss:0.26262\n",
      "[50]\tvalidation_0-mlogloss:0.00814\tvalidation_1-mlogloss:0.26316\n",
      "[51]\tvalidation_0-mlogloss:0.00797\tvalidation_1-mlogloss:0.26357\n",
      "[52]\tvalidation_0-mlogloss:0.00780\tvalidation_1-mlogloss:0.26397\n",
      "[53]\tvalidation_0-mlogloss:0.00765\tvalidation_1-mlogloss:0.26421\n",
      "[54]\tvalidation_0-mlogloss:0.00750\tvalidation_1-mlogloss:0.26484\n",
      "[55]\tvalidation_0-mlogloss:0.00736\tvalidation_1-mlogloss:0.26510\n",
      "[56]\tvalidation_0-mlogloss:0.00722\tvalidation_1-mlogloss:0.26535\n",
      "[57]\tvalidation_0-mlogloss:0.00710\tvalidation_1-mlogloss:0.26554\n",
      "[58]\tvalidation_0-mlogloss:0.00698\tvalidation_1-mlogloss:0.26545\n",
      "[59]\tvalidation_0-mlogloss:0.00686\tvalidation_1-mlogloss:0.26618\n",
      "[60]\tvalidation_0-mlogloss:0.00675\tvalidation_1-mlogloss:0.26663\n",
      "[61]\tvalidation_0-mlogloss:0.00664\tvalidation_1-mlogloss:0.26702\n",
      "[62]\tvalidation_0-mlogloss:0.00653\tvalidation_1-mlogloss:0.26758\n",
      "[63]\tvalidation_0-mlogloss:0.00643\tvalidation_1-mlogloss:0.26837\n",
      "[64]\tvalidation_0-mlogloss:0.00634\tvalidation_1-mlogloss:0.26856\n",
      "[65]\tvalidation_0-mlogloss:0.00624\tvalidation_1-mlogloss:0.26900\n",
      "[66]\tvalidation_0-mlogloss:0.00616\tvalidation_1-mlogloss:0.26906\n",
      "[67]\tvalidation_0-mlogloss:0.00607\tvalidation_1-mlogloss:0.26912\n",
      "[68]\tvalidation_0-mlogloss:0.00600\tvalidation_1-mlogloss:0.26965\n",
      "[69]\tvalidation_0-mlogloss:0.00592\tvalidation_1-mlogloss:0.27019\n",
      "[70]\tvalidation_0-mlogloss:0.00584\tvalidation_1-mlogloss:0.27056\n",
      "[71]\tvalidation_0-mlogloss:0.00577\tvalidation_1-mlogloss:0.27114\n",
      "[72]\tvalidation_0-mlogloss:0.00570\tvalidation_1-mlogloss:0.27148\n",
      "[73]\tvalidation_0-mlogloss:0.00563\tvalidation_1-mlogloss:0.27190\n",
      "[74]\tvalidation_0-mlogloss:0.00557\tvalidation_1-mlogloss:0.27207\n",
      "[75]\tvalidation_0-mlogloss:0.00550\tvalidation_1-mlogloss:0.27246\n",
      "[76]\tvalidation_0-mlogloss:0.00544\tvalidation_1-mlogloss:0.27249\n",
      "[77]\tvalidation_0-mlogloss:0.00538\tvalidation_1-mlogloss:0.27266\n",
      "[78]\tvalidation_0-mlogloss:0.00532\tvalidation_1-mlogloss:0.27292\n",
      "[79]\tvalidation_0-mlogloss:0.00527\tvalidation_1-mlogloss:0.27312\n",
      "[80]\tvalidation_0-mlogloss:0.00521\tvalidation_1-mlogloss:0.27326\n",
      "[81]\tvalidation_0-mlogloss:0.00516\tvalidation_1-mlogloss:0.27353\n",
      "[82]\tvalidation_0-mlogloss:0.00511\tvalidation_1-mlogloss:0.27383\n",
      "[83]\tvalidation_0-mlogloss:0.00506\tvalidation_1-mlogloss:0.27409\n",
      "[84]\tvalidation_0-mlogloss:0.00500\tvalidation_1-mlogloss:0.27440\n",
      "[85]\tvalidation_0-mlogloss:0.00495\tvalidation_1-mlogloss:0.27438\n",
      "[86]\tvalidation_0-mlogloss:0.00491\tvalidation_1-mlogloss:0.27463\n",
      "[87]\tvalidation_0-mlogloss:0.00487\tvalidation_1-mlogloss:0.27479\n",
      "[88]\tvalidation_0-mlogloss:0.00482\tvalidation_1-mlogloss:0.27523\n",
      "[89]\tvalidation_0-mlogloss:0.00477\tvalidation_1-mlogloss:0.27558\n",
      "[90]\tvalidation_0-mlogloss:0.00473\tvalidation_1-mlogloss:0.27583\n",
      "[91]\tvalidation_0-mlogloss:0.00468\tvalidation_1-mlogloss:0.27591\n",
      "[92]\tvalidation_0-mlogloss:0.00464\tvalidation_1-mlogloss:0.27616\n",
      "[93]\tvalidation_0-mlogloss:0.00460\tvalidation_1-mlogloss:0.27634\n",
      "[94]\tvalidation_0-mlogloss:0.00456\tvalidation_1-mlogloss:0.27660\n",
      "[95]\tvalidation_0-mlogloss:0.00453\tvalidation_1-mlogloss:0.27688\n",
      "[96]\tvalidation_0-mlogloss:0.00449\tvalidation_1-mlogloss:0.27752\n",
      "[97]\tvalidation_0-mlogloss:0.00446\tvalidation_1-mlogloss:0.27769\n",
      "[98]\tvalidation_0-mlogloss:0.00442\tvalidation_1-mlogloss:0.27789\n",
      "[99]\tvalidation_0-mlogloss:0.00439\tvalidation_1-mlogloss:0.27818\n",
      "打印XGBoost重要指标\n",
      "     features    weight\n",
      "1700    f1701  0.008035\n",
      "703      f704  0.007959\n",
      "1510    f1511  0.006522\n",
      "715      f716  0.006396\n",
      "644      f645  0.006266\n",
      "1307    f1308  0.005025\n",
      "1250    f1251  0.004699\n",
      "1803    f1804  0.004128\n",
      "1457    f1458  0.003993\n",
      "826      f827  0.003818\n",
      "1682    f1683  0.003786\n",
      "1116    f1117  0.003598\n",
      "1412    f1413  0.003450\n",
      "1652    f1653  0.003247\n",
      "171      f172  0.003094\n",
      "1223    f1224  0.003043\n",
      "1286    f1287  0.003023\n",
      "869      f870  0.002990\n",
      "46        f47  0.002974\n",
      "463      f464  0.002974\n",
      "827      f828  0.002810\n",
      "91        f92  0.002798\n",
      "1601    f1602  0.002775\n",
      "364      f365  0.002746\n",
      "1325    f1326  0.002676\n",
      "1408    f1409  0.002616\n",
      "209      f210  0.002589\n",
      "1856    f1857  0.002578\n",
      "693      f694  0.002534\n",
      "355      f356  0.002498\n",
      "1855    f1856  0.002440\n",
      "1436    f1437  0.002350\n",
      "1639    f1640  0.002336\n",
      "781      f782  0.002300\n",
      "1491    f1492  0.002287\n",
      "1172    f1173  0.002260\n",
      "1458    f1459  0.002238\n",
      "464      f465  0.002220\n",
      "812      f813  0.002212\n",
      "1072    f1073  0.002202\n",
      "506      f507  0.002190\n",
      "1097    f1098  0.002173\n",
      "923      f924  0.002109\n",
      "1695    f1696  0.002104\n",
      "1837    f1838  0.002097\n",
      "415      f416  0.002096\n",
      "265      f266  0.002067\n",
      "1261    f1262  0.002049\n",
      "215      f216  0.002018\n",
      "1818    f1819  0.002013\n"
     ]
    }
   ],
   "source": [
    "xgboost_clf = xgboost_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f510779f-fce7-47d4-bfea-4d97cefea977",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(x_train, y_train), (x_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37bcbafa-f9f6-46ad-9516-c1ba6ade46ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xost_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-6f9f5eb4f3f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxost_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xost_clf' is not defined"
     ]
    }
   ],
   "source": [
    "pre_y_test = xgbost_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08646516-661e-4491-ada4-5544c6729b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f1891</th>\n",
       "      <th>f1892</th>\n",
       "      <th>f1893</th>\n",
       "      <th>f1894</th>\n",
       "      <th>f1895</th>\n",
       "      <th>f1896</th>\n",
       "      <th>f1897</th>\n",
       "      <th>f1898</th>\n",
       "      <th>f1899</th>\n",
       "      <th>f1900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.004133</td>\n",
       "      <td>0.031950</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.084028</td>\n",
       "      <td>-0.106755</td>\n",
       "      <td>-0.198294</td>\n",
       "      <td>-0.000912</td>\n",
       "      <td>0.010045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.064062</td>\n",
       "      <td>0.084055</td>\n",
       "      <td>-0.039602</td>\n",
       "      <td>-0.011034</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>0.153470</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.032580</td>\n",
       "      <td>-0.034380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.234055</td>\n",
       "      <td>0.202590</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>0.257440</td>\n",
       "      <td>-0.008591</td>\n",
       "      <td>-0.039887</td>\n",
       "      <td>-0.009504</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.014996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198902</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>-0.186542</td>\n",
       "      <td>0.023011</td>\n",
       "      <td>-0.113903</td>\n",
       "      <td>-0.074157</td>\n",
       "      <td>0.820054</td>\n",
       "      <td>0.045937</td>\n",
       "      <td>-0.036160</td>\n",
       "      <td>-0.028256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.292311</td>\n",
       "      <td>0.244053</td>\n",
       "      <td>-0.009429</td>\n",
       "      <td>0.271757</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>-0.078286</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>-0.006165</td>\n",
       "      <td>-0.020575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175442</td>\n",
       "      <td>0.065406</td>\n",
       "      <td>-0.041244</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>-0.096559</td>\n",
       "      <td>-0.079137</td>\n",
       "      <td>0.789780</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>-0.033467</td>\n",
       "      <td>-0.100108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.245537</td>\n",
       "      <td>0.244524</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>0.386281</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>0.058923</td>\n",
       "      <td>-0.005218</td>\n",
       "      <td>-0.005565</td>\n",
       "      <td>-0.034299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157748</td>\n",
       "      <td>0.305814</td>\n",
       "      <td>-0.130900</td>\n",
       "      <td>0.045086</td>\n",
       "      <td>-0.247851</td>\n",
       "      <td>-0.131615</td>\n",
       "      <td>0.759615</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>-0.045659</td>\n",
       "      <td>-0.123342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003292</td>\n",
       "      <td>-0.010891</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>-0.004417</td>\n",
       "      <td>-0.259515</td>\n",
       "      <td>0.133029</td>\n",
       "      <td>-0.464210</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>-0.005446</td>\n",
       "      <td>0.249855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055954</td>\n",
       "      <td>-0.187867</td>\n",
       "      <td>0.014005</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.390966</td>\n",
       "      <td>-0.139071</td>\n",
       "      <td>-0.140427</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>-0.071718</td>\n",
       "      <td>-0.002881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.070719</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>-0.004329</td>\n",
       "      <td>0.881442</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>-0.002443</td>\n",
       "      <td>-0.001216</td>\n",
       "      <td>-0.625112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>-0.253492</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>-0.471886</td>\n",
       "      <td>-0.143367</td>\n",
       "      <td>-0.066733</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.118797</td>\n",
       "      <td>-0.020916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.071596</td>\n",
       "      <td>0.039163</td>\n",
       "      <td>-0.007932</td>\n",
       "      <td>0.684397</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>-0.005130</td>\n",
       "      <td>-0.003821</td>\n",
       "      <td>-0.699007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.040557</td>\n",
       "      <td>-0.309668</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>-0.497647</td>\n",
       "      <td>-0.113421</td>\n",
       "      <td>-0.026370</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>-0.042494</td>\n",
       "      <td>-0.091926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.064161</td>\n",
       "      <td>-0.001923</td>\n",
       "      <td>0.894576</td>\n",
       "      <td>-0.005141</td>\n",
       "      <td>-0.034928</td>\n",
       "      <td>-0.004715</td>\n",
       "      <td>-0.003473</td>\n",
       "      <td>-0.648881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009807</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>-0.186568</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>-0.702187</td>\n",
       "      <td>-0.083997</td>\n",
       "      <td>-0.046591</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.052006</td>\n",
       "      <td>-0.054832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.001743</td>\n",
       "      <td>-0.010931</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>0.355944</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>-0.081538</td>\n",
       "      <td>-0.007427</td>\n",
       "      <td>-0.001497</td>\n",
       "      <td>-0.138363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>-0.314343</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>-0.466908</td>\n",
       "      <td>-0.089873</td>\n",
       "      <td>-0.013782</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>0.118699</td>\n",
       "      <td>-0.021342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.109819</td>\n",
       "      <td>0.036686</td>\n",
       "      <td>-0.002889</td>\n",
       "      <td>0.819848</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.037715</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>-0.002534</td>\n",
       "      <td>-0.692687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.027521</td>\n",
       "      <td>-0.305679</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>-0.323283</td>\n",
       "      <td>-0.034847</td>\n",
       "      <td>-0.026424</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.095489</td>\n",
       "      <td>-0.063620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0   0.000033 -0.004133  0.031950 -0.000895  0.015118  0.084028 -0.106755   \n",
       "1   0.000181  0.234055  0.202590 -0.009154  0.257440 -0.008591 -0.039887   \n",
       "2   0.000188  0.292311  0.244053 -0.009429  0.271757 -0.005266 -0.078286   \n",
       "3   0.000223  0.245537  0.244524 -0.006509  0.386281  0.054393  0.058923   \n",
       "4   0.003292 -0.010891  0.011057 -0.004417 -0.259515  0.133029 -0.464210   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.000804  0.070719  0.018773 -0.004329  0.881442 -0.000350  0.029116   \n",
       "96  0.002619  0.071596  0.039163 -0.007932  0.684397  0.001810  0.004194   \n",
       "97  0.003020  0.029630  0.064161 -0.001923  0.894576 -0.005141 -0.034928   \n",
       "98  0.001743 -0.010931  0.036082 -0.004149  0.355944  0.046004 -0.081538   \n",
       "99  0.002080  0.109819  0.036686 -0.002889  0.819848 -0.000923  0.037715   \n",
       "\n",
       "          f8        f9       f10  ...     f1891     f1892     f1893     f1894  \\\n",
       "0  -0.198294 -0.000912  0.010045  ... -0.001402 -0.064062  0.084055 -0.039602   \n",
       "1  -0.009504 -0.005681 -0.014996  ...  0.198902 -0.006073 -0.186542  0.023011   \n",
       "2  -0.007095 -0.006165 -0.020575  ...  0.175442  0.065406 -0.041244  0.025119   \n",
       "3  -0.005218 -0.005565 -0.034299  ...  0.157748  0.305814 -0.130900  0.045086   \n",
       "4  -0.002968 -0.005446  0.249855  ...  0.055954 -0.187867  0.014005  0.038685   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95 -0.002443 -0.001216 -0.625112  ...  0.003353  0.010496 -0.253492  0.009834   \n",
       "96 -0.005130 -0.003821 -0.699007  ...  0.002460  0.040557 -0.309668  0.009582   \n",
       "97 -0.004715 -0.003473 -0.648881  ... -0.009807  0.017115 -0.186568  0.011872   \n",
       "98 -0.007427 -0.001497 -0.138363  ...  0.006606  0.081028 -0.314343  0.006154   \n",
       "99 -0.001972 -0.002534 -0.692687  ...  0.010687  0.027521 -0.305679  0.004627   \n",
       "\n",
       "       f1895     f1896     f1897     f1898     f1899     f1900  \n",
       "0  -0.011034 -0.902350  0.153470  0.003805  0.032580 -0.034380  \n",
       "1  -0.113903 -0.074157  0.820054  0.045937 -0.036160 -0.028256  \n",
       "2  -0.096559 -0.079137  0.789780  0.064275 -0.033467 -0.100108  \n",
       "3  -0.247851 -0.131615  0.759615  0.015326 -0.045659 -0.123342  \n",
       "4   0.390966 -0.139071 -0.140427 -0.000358 -0.071718 -0.002881  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95 -0.471886 -0.143367 -0.066733  0.002626 -0.118797 -0.020916  \n",
       "96 -0.497647 -0.113421 -0.026370  0.001468 -0.042494 -0.091926  \n",
       "97 -0.702187 -0.083997 -0.046591  0.002655 -0.052006 -0.054832  \n",
       "98 -0.466908 -0.089873 -0.013782  0.005637  0.118699 -0.021342  \n",
       "99 -0.323283 -0.034847 -0.026424  0.001977 -0.095489 -0.063620  \n",
       "\n",
       "[100 rows x 1900 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b232fc1-e7ee-4bbb-9c57-c00e2e5c0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ 测试集 ------------------------------\n",
      "打印精准率、召回率和F1值\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      3698\n",
      "           0       0.05      0.85      0.09       214\n",
      "           1       0.00      0.00      0.00        36\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.00      0.00      0.00        13\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.05      4000\n",
      "   macro avg       0.00      0.08      0.01      4000\n",
      "weighted avg       0.00      0.05      0.00      4000\n",
      "\n",
      "Precision: 0.0, Recall: 0.08, F1: 0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pre_y_test = xgboost_clf.predict(x_test)\n",
    "# 打印测试集的结果信息，包含precision、recall、f1-socre\n",
    "print(\"-\" * 30, \"测试集\", \"-\" * 30)\n",
    "print_precison_recall_f1((y_test-1), pre_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53002209-4c38-4ffb-8624-0d0c11fc05d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_y_test+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4de7115-d5ff-4f7f-9530-3eef8717e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=xgboost_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "640af2e2-9666-4a19-a97e-38f1eef85833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999536</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998039</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999494</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995280</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.996984</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.995232</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.993236</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.997971</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.974866</td>\n",
       "      <td>0.018734</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.996387</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.999536  0.000185  0.000097  0.000023  0.000031  0.000015  0.000012   \n",
       "1     0.998039  0.001149  0.000033  0.000419  0.000101  0.000040  0.000040   \n",
       "2     0.999494  0.000347  0.000066  0.000009  0.000007  0.000008  0.000006   \n",
       "3     0.995280  0.003173  0.000951  0.000150  0.000058  0.000034  0.000051   \n",
       "4     0.996984  0.001482  0.000407  0.000223  0.000129  0.000052  0.000100   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3995  0.995232  0.004096  0.000122  0.000077  0.000071  0.000041  0.000099   \n",
       "3996  0.993236  0.005212  0.000091  0.000439  0.000164  0.000097  0.000136   \n",
       "3997  0.997971  0.001500  0.000260  0.000053  0.000024  0.000014  0.000019   \n",
       "3998  0.974866  0.018734  0.000197  0.002519  0.000347  0.000336  0.001450   \n",
       "3999  0.996387  0.001642  0.000462  0.000863  0.000089  0.000134  0.000054   \n",
       "\n",
       "             7         8         9  \n",
       "0     0.000029  0.000036  0.000036  \n",
       "1     0.000045  0.000065  0.000069  \n",
       "2     0.000021  0.000020  0.000021  \n",
       "3     0.000068  0.000110  0.000125  \n",
       "4     0.000268  0.000172  0.000183  \n",
       "...        ...       ...       ...  \n",
       "3995  0.000065  0.000102  0.000096  \n",
       "3996  0.000163  0.000231  0.000232  \n",
       "3997  0.000053  0.000051  0.000054  \n",
       "3998  0.000477  0.000536  0.000537  \n",
       "3999  0.000097  0.000136  0.000136  \n",
       "\n",
       "[4000 rows x 10 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186d4cc-f502-4197-a86f-d254bad84643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
