{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f648381c-957d-4da5-b765-636e7914223e",
   "metadata": {},
   "source": [
    "# Task1. 预测是酶还是非酶，使用DeepRE数据\n",
    "\n",
    "> author: Shizhenkun   \n",
    "> email: zhenkun.shi@tib.cas.cn   \n",
    "> date: 2021-05-11  \n",
    "\n",
    "## 任务简介\n",
    "该任务通过给定蛋白序列，预测该该蛋白是酶还是非酶。本任务所使用的数据集为DeepRE，数据集中有标定好的数据。\n",
    "\n",
    "参考文章：DEEPre: sequence-based enzyme EC number prediction by deep learning  \n",
    "URL：https://pubmed.ncbi.nlm.nih.gov/29069344/   \n",
    "发表日期：2018年3月\n",
    "\n",
    "## 数据构建方法\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.1 Datasets \n",
    "\n",
    "<span style='font-family:\"Source Code Pro\"; background:yellow'>We adopt three datasets in this paper</span><span  style='font-family:\"Source Code Pro\"'>. <span style='background: aqua'>The first dataset is a widely used one from (Shen and Chou, 2007), constructed from the ENZYME database (released on May 1, 2007)</span>, <span style='background:silver'>with 40% sequence similarity cutoff</span>. More details of that dataset could be referred to (Shen and Chou, 2007). This dataset is denoted as the KNN dataset in the rest of the paper.</span>\n",
    "\n",
    "Following the same procedure of constructing the KNN dataset, we constructed a larger dataset using up-to-date databases. The steps of constructing the dataset are as follows:\n",
    "\n",
    "i. <span style='color:red;background:silver'>The SWISS-PROT (released on September 7, 2016) database was separated into enzymes and non-enzymes based on the\n",
    "annotation.</span>\n",
    "\n",
    "ii. <u>To guarantee the uniqueness and correctness</u>, <span style='background:lime'>enzyme sequences with more than one set of EC numbers</span> or <span style='background:red'>incomplete EC number annotation</span> <u>were excluded</u>.</span>\n",
    "\n",
    "iii. To avoid fragment data, enzyme sequences annotated with ‘fragment’ or <span style='background:red'>with &lt;50 amino acids were excluded</span>. Enzyme sequences with <span style='color:white;background:teal'>more than 5000 amino\n",
    "acids were also excluded.</span>\n",
    "\n",
    "iv. <span style='color:white;background:purple'>To remove redundancy bias, we used CD-HIT (Fu et al., 2012) with 40% similarity threshold to sift upon the raw dataset,\n",
    "resulting in 22168 low-homology enzyme sequences.</span>\n",
    "\n",
    "v. To construct the <span style='background:yellow'>non-enzyme part</span>, 22168 non-enzyme protein sequences were <span style='background:yellow'>randomly\n",
    "collected</span> from the SWISS-PROT (released on September 7, 2016) non-enzyme part, <span style='background:fuchsia'>which were also subject to the (ii–iv) steps.</span>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 数据统计\n",
    "- 数据源DeepRE，共有数据44,336条，其中有酶数据22,168条，非酶数据22,168条。\n",
    "- ～90%作为训练集，～10%作为测试集, 训练集数据39902条，测试集数据4434条。\n",
    "\n",
    "## 实验结果\n",
    "### 1. 同源比对\n",
    "|ITEM                   |VALUE               |\n",
    "|:----------------------|-------------------:|\n",
    "|Total query records    | 4432               |\n",
    "|Matched records        | 1348               |\n",
    "|Accuracy               | 0.2441(1082/4432)  |\n",
    "|Pricision              | 0.8028(1082/1348)  |\n",
    "|Recall                 | 0.3042(1348/4432)  |\n",
    "\n",
    "### 2. 直接计算\n",
    "\n",
    "|baslineName  |\t accuracy | precision(PPV)| NPV \t  |\t recall \t| f1 \t\t| auroc \t\t| auprc \t|\t confusion Matrix                   |\n",
    "|:-----------:|:---------:|:-------------:|:---------:|:-----------:|:---------:|:-------------:|:---------:|--------------------------------------:|\n",
    "|lr \t\t  |\t0.602211  |0.582454 \t  |\t0.634421  |\t0.722022 \t|\t0.644771| \t0.641392 \t|0.587693 \t| tp: 1600 fp: 1147 fn: 616 tn: 1069    |\n",
    "|xg \t\t  |\t0.671706  |0.646854 \t  |\t0.706681  |\t0.756318 \t|\t0.697316| \t0.732797 \t|0.701976 \t| tp: 1676 fp: 915 fn: 540 tn: 1301     |\n",
    "|dt \t\t  |\t0.555731  |0.555011 \t  |\t0.556470  |\t0.562274 \t|\t0.558619| \t0.555731 \t|0.530931 \t| tp: 1246 fp: 999 fn: 970 tn: 1217\t\t|\n",
    "|rf \t\t  |\t0.644856  |0.608008 \t  |\t0.719863  |\t0.815433 \t|\t0.696608| \t0.684255 \t|0.626909 \t| tp: 1807 fp: 1165 fn: 409 tn: 1051\t|\n",
    "|gbdt \t\t  |\t0.668998  |0.611691 \t  |\t0.847081  |\t0.925542 \t|\t0.736577| \t0.722414 \t|0.667868 \t| tp: 2051 fp: 1302 fn: 165 tn: 914 \t| \n",
    "\n",
    "### 3. 经过Unirep后再计算\n",
    "\n",
    "|baslineName  |\t accuracy | precision(PPV)| NPV \t  |\t recall \t| f1 \t\t| auroc \t\t| auprc \t|\t confusion Matrix                   |\n",
    "|:-----------:|:---------:|:-------------:|:---------:|:-----------:|:---------:|:-------------:|:---------:|--------------------------------------:|\n",
    "|lr \t\t  |\t0.792195  |\t0.838294 \t  |\t0.747601  |\t0.762635 \t|0.798677 \t|0.868101 \t    |0.873953 \t| tp: 1690 fp: 326 fn: 526 tn: 1558     |\n",
    "|xg \t\t  |\t0.787561  |\t0.835746 \t  |\t0.741536  |\t0.755415 \t|0.793553 \t|0.870851 \t    |0.863003 \t| tp: 1674 fp: 329 fn: 542 tn: 1555     |\n",
    "|dt \t\t  |\t0.682439  |\t0.725568 \t  |\t0.640309  |\t0.663357 \t|0.693069 \t|0.684120 \t    |0.663262 \t| tp: 1470 fp: 556 fn: 746 tn: 1328     |\n",
    "|rf \t\t  |\t0.779756  |\t0.857766 \t  |\t0.716556  |\t0.710289 \t|0.777092 \t|0.868243 \t    |0.857856 \t| tp: 1574 fp: 261 fn: 642 tn: 1623     |\n",
    "|gbdt         |\t0.806829  |\t0.856000 \t  |\t0.760000  |\t0.772563 \t|0.812144 \t|0.887189 \t    |0.882337 \t| tp: 1712 fp: 288 fn: 504 tn: 156      |  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 实验结论\n",
    "\n",
    "1. 同源比对结果对<span style='background:yellow'>数据的依赖性强，且预测结果的稳定性差。</span>\n",
    "2. 机器学习算法预对对<span style='background:yellow'>数据的依赖性较弱，且预测结果稳定性较强。</span>\n",
    "3. 在机器学习算法中，特征工程尤为重要，<span style='background:yellow'>好的序列表征方法对预测结果增益明显，初步提升效果约15%。</span> \n",
    "4. Unirep特征计算方法可以摒弃对序列长度的筛选。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d6e1d8-cf2b-4ea7-a2d5-8dee4f0935f1",
   "metadata": {},
   "source": [
    "### 0. 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938e913b-d2cb-446d-b7d1-6b6155e81da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import gzip\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import datetime\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../../tools/\")\n",
    "import commontools\n",
    "import funclib\n",
    "\n",
    "from pyecharts.globals import CurrentConfig, NotebookType\n",
    "CurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_LAB\n",
    "\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Bar\n",
    "from pyecharts.faker import Faker\n",
    "from pyecharts.globals import ThemeType\n",
    "\n",
    "from jax_unirep import get_reps\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3780d50c-69d7-4e72-869a-ed105b0c99cc",
   "metadata": {},
   "source": [
    "### 1. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e5d72d-46a3-4e3a-a625-99b7d1e8beba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"./data/deepre/new_data_label_sequence.txt\")\n",
    "line = f.readline()\n",
    "\n",
    "counter = 0\n",
    "enzyme = []\n",
    "while line:\n",
    "    seq = line.split('>')[1].replace('\\n','')\n",
    "    enzyme.append([seq,1])\n",
    "    line = f.readline()\n",
    "    counter +=1\n",
    "#     if counter ==5:\n",
    "#         break\n",
    "f.close()\n",
    "\n",
    "enzyme = pd.DataFrame(enzyme)\n",
    "enzyme.columns=['seq', 'label']\n",
    "enzyme['seqlength'] = enzyme['seq'].map(lambda x : len(x))\n",
    "\n",
    "\n",
    "f = open(\"./data/deepre/non_enzyme_new_data_sequence.txt\")\n",
    "line = f.readline()\n",
    "\n",
    "counter = 0\n",
    "non_enzyme = []\n",
    "while line:\n",
    "    seq = line.split('>')[1].replace('\\n','')\n",
    "    non_enzyme.append([seq,0])\n",
    "    line = f.readline()\n",
    "    counter +=1\n",
    "#     if counter ==5:\n",
    "#         break\n",
    "f.close()\n",
    "\n",
    "non_enzyme = pd.DataFrame(non_enzyme)\n",
    "non_enzyme.columns=['seq', 'label']\n",
    "non_enzyme['seqlength'] = non_enzyme['seq'].map(lambda x : len(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5fd5c-4943-4dd1-bd61-60500af9483c",
   "metadata": {},
   "source": [
    "###  2.划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c4a2ee-26ee-481f-80ff-bcdceac7cb62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = enzyme.iloc[:19951,]\n",
    "test = enzyme.iloc[19951:-1,]\n",
    "\n",
    "train = train.append(non_enzyme.iloc[:19951,])\n",
    "test = test.append(non_enzyme.iloc[19951:-1,])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "train['id'] = train.index\n",
    "test['id'] = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3c875244-461d-467c-8318-a6efbd2ce782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "Write finished\n"
     ]
    }
   ],
   "source": [
    "train.to_csv('./data/train_deepec.tsv', sep='\\t', index=0)\n",
    "test.to_csv('./data/test_deepec.tsv', sep='\\t',  index=0)\n",
    "\n",
    "funclib.table2fasta(train, './data/train_deepec.fasta')\n",
    "funclib.table2fasta(test, './data/test_deepec.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b17d4-149c-4ce1-b162-15dfeb88a5b6",
   "metadata": {},
   "source": [
    "### 3. 同源比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6e1dc097-aaae-403a-a9cb-82940b90277a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diamond v2.0.8.146 (C) Max Planck Society for the Advancement of Science\n",
      "Documentation, support and updates available at http://www.diamondsearch.org\n",
      "\n",
      "#CPU threads: 32\n",
      "Scoring parameters: (Matrix=BLOSUM62 Lambda=0.267 K=0.041 Penalties=11/1)\n",
      "Database input file: ./data/train_deepec.fasta\n",
      "Opening the database file...  [0.406s]\n",
      "Loading sequences...  [0.059s]\n",
      "Masking sequences...  [0.052s]\n",
      "Writing sequences...  [0.008s]\n",
      "Hashing sequences...  [0.004s]\n",
      "Loading sequences...  [0s]\n",
      "Writing trailer...  [0s]\n",
      "Closing the input file...  [0.001s]\n",
      "Closing the database file...  [0.026s]\n",
      "Database hash = 73b25e3f21156a992e5d170dbc7223bd\n",
      "Processed 39902 sequences, 17343489 letters.\n",
      "Total time = 0.559s\n",
      "diamond v2.0.8.146 (C) Max Planck Society for the Advancement of Science\n",
      "Documentation, support and updates available at http://www.diamondsearch.org\n",
      "\n",
      "#CPU threads: 32\n",
      "Scoring parameters: (Matrix=BLOSUM62 Lambda=0.267 K=0.041 Penalties=11/1)\n",
      "Temporary directory: ./data\n",
      "#Target sequences to report alignments for: 1\n",
      "Opening the database...  [0.022s]\n",
      "Database: ./data/train_deepec.dmnd (type: Diamond database, sequences: 39902, letters: 17343489)\n",
      "Block size = 5000000000\n",
      "Opening the input file...  [0.001s]\n",
      "Opening the output file...  [0.012s]\n",
      "Loading query sequences...  [0.009s]\n",
      "Masking queries...  [0.017s]\n",
      "Building query seed set...  [0.02s]\n",
      "Algorithm: Double-indexed\n",
      "Building query histograms...  [0.006s]\n",
      "Allocating buffers...  [0s]\n",
      "Loading reference sequences...  [0.025s]\n",
      "Masking reference...  [0.048s]\n",
      "Initializing temporary storage...  [0.058s]\n",
      "Building reference histograms...  [0.029s]\n",
      "Allocating buffers...  [0s]\n",
      "Processing query block 1, reference block 1/1, shape 1/2.\n",
      "Building reference seed array...  [0.033s]\n",
      "Building query seed array...  [0.011s]\n",
      "Computing hash join...  [0.013s]\n",
      "Building seed filter...  [0.002s]\n",
      "Searching alignments...  [0.002s]\n",
      "Processing query block 1, reference block 1/1, shape 2/2.\n",
      "Building reference seed array...  [0.024s]\n",
      "Building query seed array...  [0.005s]\n",
      "Computing hash join...  [0.012s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.002s]\n",
      "Deallocating buffers...  [0.007s]\n",
      "Clearing query masking...  [0s]\n",
      "Computing alignments...  [0.079s]\n",
      "Deallocating reference...  [0s]\n",
      "Loading reference sequences...  [0s]\n",
      "Deallocating buffers...  [0.001s]\n",
      "Deallocating queries...  [0s]\n",
      "Loading query sequences...  [0s]\n",
      "Closing the input file...  [0s]\n",
      "Closing the output file...  [0s]\n",
      "Closing the database file...  [0.001s]\n",
      "Deallocating taxonomy...  [0s]\n",
      "Total time = 0.564s\n",
      "Reported 1349 pairwise alignments, 1349 HSPs.\n",
      "1349 queries aligned.\n"
     ]
    }
   ],
   "source": [
    "! diamond makedb --in ./data/train_deepec.fasta -d ./data/train_deepec.dmnd     #建库\n",
    "! diamond blastp -d ./data/train_deepec.dmnd  -q ./data/test_deepec.fasta -o ./data/test_deepec_fasta_results.tsv -b5 -c1 -k 1  #生成比对文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6626a11a-153b-4585-a26a-76a74fa34415",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "      <th>seqlength</th>\n",
       "      <th>id</th>\n",
       "      <th>sseqid</th>\n",
       "      <th>pident</th>\n",
       "      <th>length</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gapopen</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>sstart</th>\n",
       "      <th>send</th>\n",
       "      <th>evalue</th>\n",
       "      <th>bitscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MQRPGPFSTLYGRVLAPLPGRAGGAASGGGGNSWDLPGSHVRLPGR...</td>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "      <td>19941</td>\n",
       "      <td>45.5</td>\n",
       "      <td>235</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>306</td>\n",
       "      <td>31</td>\n",
       "      <td>265</td>\n",
       "      <td>3.280000e-66</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSEAKRRAAEKAIEYVENDMIIGVGTGSTVAYFIDALGHTPKRIKG...</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>41.4</td>\n",
       "      <td>220</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>208</td>\n",
       "      <td>11</td>\n",
       "      <td>227</td>\n",
       "      <td>1.190000e-38</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSKQPENSFSSDKFFPIKQKLALEAVALVEPGMCVGLGSGSTAREF...</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>4</td>\n",
       "      <td>19942</td>\n",
       "      <td>38.4</td>\n",
       "      <td>219</td>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>234</td>\n",
       "      <td>9</td>\n",
       "      <td>226</td>\n",
       "      <td>3.710000e-41</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSQKPTSHPYKPNMTQDELKALVGQAALPYVEPGSIVGVGTGSTVN...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>19942</td>\n",
       "      <td>39.4</td>\n",
       "      <td>226</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>238</td>\n",
       "      <td>6</td>\n",
       "      <td>227</td>\n",
       "      <td>1.380000e-40</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSVTPIEELPSLGDALEDAKRAASYRAVDENLDPAKHRVVGIGSGS...</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>6</td>\n",
       "      <td>19941</td>\n",
       "      <td>52.0</td>\n",
       "      <td>244</td>\n",
       "      <td>106</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>249</td>\n",
       "      <td>27</td>\n",
       "      <td>261</td>\n",
       "      <td>9.250000e-73</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  label  seqlength  id  \\\n",
       "0  MQRPGPFSTLYGRVLAPLPGRAGGAASGGGGNSWDLPGSHVRLPGR...      1        311   1   \n",
       "1  MSEAKRRAAEKAIEYVENDMIIGVGTGSTVAYFIDALGHTPKRIKG...      1        215   2   \n",
       "2  MSKQPENSFSSDKFFPIKQKLALEAVALVEPGMCVGLGSGSTAREF...      1        242   4   \n",
       "3  MSQKPTSHPYKPNMTQDELKALVGQAALPYVEPGSIVGVGTGSTVN...      1        240   5   \n",
       "4  MSVTPIEELPSLGDALEDAKRAASYRAVDENLDPAKHRVVGIGSGS...      1        255   6   \n",
       "\n",
       "   sseqid  pident  length  mismatch  gapopen  qstart  qend  sstart  send  \\\n",
       "0   19941    45.5     235       125        2      75   306      31   265   \n",
       "1   19950    41.4     220       111        5       4   208      11   227   \n",
       "2   19942    38.4     219       133        2      17   234       9   226   \n",
       "3   19942    39.4     226       130        3      16   238       6   227   \n",
       "4   19941    52.0     244       106        8       8   249      27   261   \n",
       "\n",
       "         evalue  bitscore  \n",
       "0  3.280000e-66     209.0  \n",
       "1  1.190000e-38     134.0  \n",
       "2  3.710000e-41     140.0  \n",
       "3  1.380000e-40     139.0  \n",
       "4  9.250000e-73     224.0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读入比对结果\n",
    "res_data = pd.read_csv('./data/test_deepec_fasta_results.tsv',header=0, sep='\\t', names=['id', 'sseqid', 'pident', 'length','mismatch','gapopen','qstart','qend','sstart','send','evalue','bitscore'])\n",
    "\n",
    "#匹配查询结果\n",
    "data_match = pd.merge(test,res_data, on=['id'], how='inner')\n",
    "data_match.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "35ceabee-120b-41b2-a080-33068e8d5fff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "      <th>seqlength</th>\n",
       "      <th>id</th>\n",
       "      <th>sseqid</th>\n",
       "      <th>pident</th>\n",
       "      <th>length</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gapopen</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>sstart</th>\n",
       "      <th>send</th>\n",
       "      <th>evalue</th>\n",
       "      <th>bitscore</th>\n",
       "      <th>q_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MQRPGPFSTLYGRVLAPLPGRAGGAASGGGGNSWDLPGSHVRLPGR...</td>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "      <td>19941</td>\n",
       "      <td>45.5</td>\n",
       "      <td>235</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>306</td>\n",
       "      <td>31</td>\n",
       "      <td>265</td>\n",
       "      <td>3.280000e-66</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSEAKRRAAEKAIEYVENDMIIGVGTGSTVAYFIDALGHTPKRIKG...</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>41.4</td>\n",
       "      <td>220</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>208</td>\n",
       "      <td>11</td>\n",
       "      <td>227</td>\n",
       "      <td>1.190000e-38</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSKQPENSFSSDKFFPIKQKLALEAVALVEPGMCVGLGSGSTAREF...</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>4</td>\n",
       "      <td>19942</td>\n",
       "      <td>38.4</td>\n",
       "      <td>219</td>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>234</td>\n",
       "      <td>9</td>\n",
       "      <td>226</td>\n",
       "      <td>3.710000e-41</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  label  seqlength  id  \\\n",
       "0  MQRPGPFSTLYGRVLAPLPGRAGGAASGGGGNSWDLPGSHVRLPGR...      1        311   1   \n",
       "1  MSEAKRRAAEKAIEYVENDMIIGVGTGSTVAYFIDALGHTPKRIKG...      1        215   2   \n",
       "2  MSKQPENSFSSDKFFPIKQKLALEAVALVEPGMCVGLGSGSTAREF...      1        242   4   \n",
       "\n",
       "   sseqid  pident  length  mismatch  gapopen  qstart  qend  sstart  send  \\\n",
       "0   19941    45.5     235       125        2      75   306      31   265   \n",
       "1   19950    41.4     220       111        5       4   208      11   227   \n",
       "2   19942    38.4     219       133        2      17   234       9   226   \n",
       "\n",
       "         evalue  bitscore  q_label  \n",
       "0  3.280000e-66     209.0        1  \n",
       "1  1.190000e-38     134.0        1  \n",
       "2  3.710000e-41     140.0        1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter =0\n",
    "resArray =[]\n",
    "for i in range(len(res_data)):\n",
    "    counter+=1\n",
    "    mn = train[train['id']== res_data['sseqid'][i]]['label'].values\n",
    "    resArray.append(mn)\n",
    "    if counter %1000 ==0:\n",
    "        print(counter)\n",
    "data_match['q_label']=np.array(resArray) \n",
    "data_match.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bccebf00-c844-4583-a815-21eb583b474f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total query records are: 4432\n",
      "Matched records are: 1348\n",
      "Accuracy: 0.24413357400722022(1082/4432)\n",
      "Pricision: 0.8026706231454006(1082/1348)\n",
      "Recall: 0.30415162454873645(1348/4432)\n"
     ]
    }
   ],
   "source": [
    "# 计算指标\n",
    "data_match['iscorrect'] = data_match[['label', 'q_label']].apply(lambda x: x['label'] == x['q_label'], axis=1) #判断EC号是否一致\n",
    "correct = sum(data_match['iscorrect'])\n",
    "find  = len(data_match)\n",
    "total = len(test)\n",
    "print('Total query records are: {0}'.format(total))\n",
    "print('Matched records are: {0}'.format(find))\n",
    "print('Accuracy: {0}({1}/{2})'.format(correct/total, correct, total))\n",
    "print('Pricision: {0}({1}/{2})'.format(correct/find, correct, find))\n",
    "print('Recall: {0}({1}/{2})'.format(find/total, find, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ce381-5777-4ddd-90e8-20efd290ab5a",
   "metadata": {},
   "source": [
    "### 4. 传统机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3650a42e-654d-488d-824d-1b6a2ca6cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train[['id', 'label','seq', 'seqlength']].reset_index(drop=True)\n",
    "testset = test[['id', 'label','seq', 'seqlength']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3c631be0-a79f-4c86-929d-995e3020f1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 1000 #定义序列最长的长度\n",
    "trainset.seq = trainset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))\n",
    "testset.seq = testset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c72f3f09-49f8-48d2-8b7c-55e78bbefcd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_train = funclib.dna_onehot(trainset) #训练集编码\n",
    "f_test = funclib.dna_onehot(testset) #测试集编码\n",
    "\n",
    "train_full = pd.concat([trainset, f_train], axis=1, join='inner' ) #拼合训练集\n",
    "test_full = pd.concat([testset, f_test], axis=1, join='inner' )    #拼合测试集\n",
    "\n",
    "\n",
    "X_train = train_full.iloc[:,4:]\n",
    "X_test = test_full.iloc[:,4:]\n",
    "Y_train = train_full.label.astype('int')\n",
    "Y_test = test_full.label.astype('int')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "344c7709-fc1d-4034-894b-9c38952dee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t auroc \t\t auprc \t\t confusion Matrix\n",
      "lr \t\t0.602211 \t0.582454 \t\t0.634421 \t0.722022 \t0.644771 \t0.641392 \t0.587693 \t tp: 1600 fp: 1147 fn: 616 tn: 1069\n",
      "[14:03:34] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xg \t\t0.671706 \t0.646854 \t\t0.706681 \t0.756318 \t0.697316 \t0.732797 \t0.701976 \t tp: 1676 fp: 915 fn: 540 tn: 1301\n",
      "dt \t\t0.555731 \t0.555011 \t\t0.556470 \t0.562274 \t0.558619 \t0.555731 \t0.530931 \t tp: 1246 fp: 999 fn: 970 tn: 1217\n",
      "rf \t\t0.644856 \t0.608008 \t\t0.719863 \t0.815433 \t0.696608 \t0.684255 \t0.626909 \t tp: 1807 fp: 1165 fn: 409 tn: 1051\n",
      "gbdt \t\t0.668998 \t0.611691 \t\t0.847081 \t0.925542 \t0.736577 \t0.722414 \t0.667868 \t tp: 2051 fp: 1302 fn: 165 tn: 914\n"
     ]
    }
   ],
   "source": [
    "methods=['lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', 'auroc','\\t\\t', 'auprc', '\\t\\t confusion Matrix')\n",
    "for method in methods:\n",
    "    funclib.evaluate(method, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee06e7-c886-46a9-a329-d37611f1b6a1",
   "metadata": {},
   "source": [
    "### 5. UniRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d0b5fddc-f224-4de2-ba28-ba3ba1403227",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainset['seq']\n",
    "Y_train = trainset.label.astype('int')\n",
    "\n",
    "X_test = testset['seq']\n",
    "Y_test = testset.label.astype('int')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be64100-649e-4a4d-b11a-27b4b9e9df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res = []\n",
    "counter = 0\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    train_h_avg, train_h_final, train_c_final= get_reps(X_train[i])\n",
    "    X_train_res.append(train_h_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "89cb2167-2112-44ac-b78e-4225284853e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 500 # 划分的子文件大小\n",
    "\n",
    "# 训练集\n",
    "!rm -rf ./data/deepre/train_*.tsv\n",
    "counter = 1\n",
    "for i in range(0, len(train), step):\n",
    "    save = train[i:i+step].iloc[:,0:2]\n",
    "    save.to_csv('./data/deepre/train_{0}.tsv'.format(counter), sep='\\t',  index=0)\n",
    "    counter +=1\n",
    "#测试集    \n",
    "!rm -rf ./data/deepre/test_*.tsv\n",
    "counter = 1\n",
    "for i in range(0, len(test), step):\n",
    "    save = test[i:i+step].iloc[:,0:2]\n",
    "    save.to_csv('./data/deepre/test_{0}.tsv'.format(counter), sep='\\t',  index=0)\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d9d0f77-e5ef-4c8c-ae26-89ccd94fe4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Unirep后的结果\n",
    "\n",
    "# 加载训练集\n",
    "\n",
    "train_uni = pd.DataFrame()\n",
    "for i in range (1,81):\n",
    "    load=pd.read_csv('./data/deepre/res/train_'+str(i)+'.tsv' ,sep='\\t', header =0)\n",
    "    train_uni = pd.concat([train_uni, load])\n",
    "    \n",
    "# 加载测试集\n",
    "test_uni = pd.DataFrame()\n",
    "for i in range (1,10):\n",
    "    load=pd.read_csv('./data/deepre/res/test_'+str(i)+'.tsv' ,sep='\\t', header =0)\n",
    "    test_uni = pd.concat([test_uni, load])\n",
    "    \n",
    "    \n",
    "train_uni = shuffle(train_uni)\n",
    "test_uni = shuffle(test_uni)\n",
    "train_uni = train_uni.reset_index(drop=True) \n",
    "test_uni = test_uni.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf82285-de41-47f1-9f13-f6184cee8de5",
   "metadata": {},
   "source": [
    "#### 原始特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "248b159d-c580-4692-a1d1-3d411104eaa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t auroc \t\t auprc \t\t confusion Matrix\n",
      "lr \t\t0.792195 \t0.838294 \t\t0.747601 \t0.762635 \t0.798677 \t0.868101 \t0.873953 \t tp: 1690 fp: 326 fn: 526 tn: 1558\n",
      "[11:26:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xg \t\t0.787561 \t0.835746 \t\t0.741536 \t0.755415 \t0.793553 \t0.870851 \t0.863003 \t tp: 1674 fp: 329 fn: 542 tn: 1555\n",
      "dt \t\t0.682439 \t0.725568 \t\t0.640309 \t0.663357 \t0.693069 \t0.684120 \t0.663262 \t tp: 1470 fp: 556 fn: 746 tn: 1328\n",
      "rf \t\t0.779756 \t0.857766 \t\t0.716556 \t0.710289 \t0.777092 \t0.868243 \t0.857856 \t tp: 1574 fp: 261 fn: 642 tn: 1623\n",
      "gbdt \t\t0.806829 \t0.856000 \t\t0.760000 \t0.772563 \t0.812144 \t0.887189 \t0.882337 \t tp: 1712 fp: 288 fn: 504 tn: 1596\n"
     ]
    }
   ],
   "source": [
    "X_train_uni = np.array(train_uni.iloc[:,0:1900])\n",
    "X_test_uni = np.array(test_uni.iloc[:,0:1900])\n",
    "\n",
    "Y_train_uni = np.array(train_uni.iloc[:,1900].astype('int'))\n",
    "Y_test_uni = np.array(test_uni.iloc[:,1900].astype('int'))\n",
    "\n",
    "methods=['lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', 'auroc','\\t\\t', 'auprc', '\\t\\t confusion Matrix')\n",
    "for method in methods:\n",
    "    funclib.evaluate(method, X_train_uni, Y_train_uni, X_test_uni, Y_test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f26e5f-23e4-4fe2-b7e5-8b53ad62f19e",
   "metadata": {},
   "source": [
    "#### 特征缩减到1700维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dfa18e28-b7d5-4d17-b15c-a7362035c129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t auroc \t\t auprc \t\t confusion Matrix\n",
      "lr \t\t0.793171 \t0.838279 \t\t0.749278 \t0.764892 \t0.799906 \t0.869521 \t0.876673 \t tp: 1695 fp: 327 fn: 521 tn: 1557\n",
      "[13:41:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xg \t\t0.794878 \t0.840853 \t\t0.750360 \t0.765343 \t0.801323 \t0.875258 \t0.872488 \t tp: 1696 fp: 321 fn: 520 tn: 1563\n",
      "dt \t\t0.673659 \t0.716043 \t\t0.632012 \t0.656588 \t0.685028 \t0.675163 \t0.655756 \t tp: 1455 fp: 577 fn: 761 tn: 1307\n",
      "rf \t\t0.778537 \t0.861726 \t\t0.712914 \t0.703069 \t0.774354 \t0.866181 \t0.858129 \t tp: 1558 fp: 250 fn: 658 tn: 1634\n",
      "gbdt \t\t0.800244 \t0.852600 \t\t0.751298 \t0.762184 \t0.804861 \t0.883880 \t0.876645 \t tp: 1689 fp: 292 fn: 527 tn: 1592\n"
     ]
    }
   ],
   "source": [
    "X_train_uni = np.array(train_uni.iloc[:,0:1700])\n",
    "X_test_uni = np.array(test_uni.iloc[:,0:1700])\n",
    "\n",
    "Y_train_uni = np.array(train_uni.iloc[:,1900].astype('int'))\n",
    "Y_test_uni = np.array(test_uni.iloc[:,1900].astype('int'))\n",
    "\n",
    "methods=['lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', 'auroc','\\t\\t', 'auprc', '\\t\\t confusion Matrix')\n",
    "for method in methods:\n",
    "    funclib.evaluate(method, X_train_uni, Y_train_uni, X_test_uni, Y_test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075fff24-bc23-4741-af34-8827dc1b60ae",
   "metadata": {},
   "source": [
    "#### 特征缩减到1000维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4d2a6259-4284-4eb3-a0b9-69f4a13dc66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t auroc \t\t auprc \t\t confusion Matrix\n",
      "lr \t\t0.782195 \t0.835957 \t\t0.732520 \t0.742780 \t0.786619 \t0.861076 \t0.867129 \t tp: 1646 fp: 323 fn: 570 tn: 1561\n",
      "[14:50:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xg \t\t0.786098 \t0.842806 \t\t0.734513 \t0.742780 \t0.789638 \t0.865958 \t0.866846 \t tp: 1646 fp: 307 fn: 570 tn: 1577\n",
      "dt \t\t0.660000 \t0.701668 \t\t0.618817 \t0.645307 \t0.672308 \t0.661295 \t0.644499 \t tp: 1430 fp: 608 fn: 786 tn: 1276\n",
      "rf \t\t0.766585 \t0.846832 \t\t0.702845 \t0.693592 \t0.762590 \t0.858289 \t0.847951 \t tp: 1537 fp: 278 fn: 679 tn: 1606\n",
      "gbdt \t\t0.792439 \t0.845570 \t\t0.743059 \t0.753610 \t0.796946 \t0.873366 \t0.872534 \t tp: 1670 fp: 305 fn: 546 tn: 1579\n"
     ]
    }
   ],
   "source": [
    "X_train_uni = np.array(train_uni.iloc[:,0:1000])\n",
    "X_test_uni = np.array(test_uni.iloc[:,0:1000])\n",
    "\n",
    "Y_train_uni = np.array(train_uni.iloc[:,1900].astype('int'))\n",
    "Y_test_uni = np.array(test_uni.iloc[:,1900].astype('int'))\n",
    "\n",
    "methods=['lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', 'auroc','\\t\\t', 'auprc', '\\t\\t confusion Matrix')\n",
    "for method in methods:\n",
    "    funclib.evaluate(method, X_train_uni, Y_train_uni, X_test_uni, Y_test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45a03a-34ae-409f-a1e3-d4674e229d7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### tanh 激活\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e5b7423d-7205-4079-ba38-af0c10be1d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t auroc \t\t auprc \t\t confusion Matrix\n",
      "lr \t\t0.792683 \t0.838454 \t\t0.748319 \t0.763538 \t0.799244 \t0.868518 \t0.874530 \t tp: 1692 fp: 326 fn: 524 tn: 1558\n",
      "[13:00:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xg \t\t0.787561 \t0.835746 \t\t0.741536 \t0.755415 \t0.793553 \t0.870885 \t0.863034 \t tp: 1674 fp: 329 fn: 542 tn: 1555\n",
      "dt \t\t0.670732 \t0.715637 \t\t0.627629 \t0.648466 \t0.680398 \t0.672694 \t0.654066 \t tp: 1437 fp: 571 fn: 779 tn: 1313\n",
      "rf \t\t0.780488 \t0.858779 \t\t0.717123 \t0.710740 \t0.777778 \t0.868492 \t0.858102 \t tp: 1575 fp: 259 fn: 641 tn: 1625\n",
      "gbdt \t\t0.806829 \t0.856000 \t\t0.760000 \t0.772563 \t0.812144 \t0.887189 \t0.882337 \t tp: 1712 fp: 288 fn: 504 tn: 1596\n"
     ]
    }
   ],
   "source": [
    "X_train_uni = np.array(train_uni.iloc[:,0:1900])\n",
    "X_test_uni = np.array(test_uni.iloc[:,0:1900])\n",
    "Y_train_uni = np.array(train_uni.iloc[:,1900].astype('int'))\n",
    "Y_test_uni = np.array(test_uni.iloc[:,1900].astype('int'))\n",
    "\n",
    "X_train_uni = torch.tanh(torch.from_numpy(X_train_uni)).data.numpy()\n",
    "X_test_uni = torch.tanh(torch.from_numpy(X_test_uni)).data.numpy()\n",
    "\n",
    "\n",
    "methods=['lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', 'auroc','\\t\\t', 'auprc', '\\t\\t confusion Matrix')\n",
    "for method in methods:\n",
    "    funclib.evaluate(method, X_train_uni, Y_train_uni, X_test_uni, Y_test_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38dcd5-cca2-4619-b67a-9f95c138ca87",
   "metadata": {},
   "source": [
    "#### Sigmoid 激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0300ea37-aea6-4d86-b4a9-bf4e71246abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t auroc \t\t auprc \t\t confusion Matrix\n",
      "lr \t\t0.798780 \t0.847576 \t\t0.752263 \t0.765343 \t0.804363 \t0.874626 \t0.878341 \t tp: 1696 fp: 305 fn: 520 tn: 1579\n",
      "[14:19:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xg \t\t0.784634 \t0.839186 \t\t0.734426 \t0.744134 \t0.788807 \t0.868557 \t0.861314 \t tp: 1649 fp: 316 fn: 567 tn: 1568\n",
      "dt \t\t0.667805 \t0.712227 \t\t0.625000 \t0.646661 \t0.677862 \t0.669668 \t0.651545 \t tp: 1433 fp: 579 fn: 783 tn: 1305\n",
      "rf \t\t0.775122 \t0.855886 \t\t0.710780 \t0.702166 \t0.771443 \t0.862507 \t0.853523 \t tp: 1556 fp: 262 fn: 660 tn: 1622\n",
      "gbdt \t\t0.799512 \t0.850957 \t\t0.751183 \t0.762635 \t0.804379 \t0.885764 \t0.879943 \t tp: 1690 fp: 296 fn: 526 tn: 1588\n"
     ]
    }
   ],
   "source": [
    "X_train_uni = torch.sigmoid(torch.from_numpy(X_train_uni)).data.numpy()\n",
    "X_test_uni = torch.sigmoid(torch.from_numpy(X_test_uni)).data.numpy()\n",
    "\n",
    "methods=['lr', 'xg', 'dt', 'rf', 'gbdt']\n",
    "print('baslineName', '\\t', 'accuracy','\\t', 'precision(PPV) \\t NPV \\t\\t', 'recall','\\t', 'f1', '\\t\\t', 'auroc','\\t\\t', 'auprc', '\\t\\t confusion Matrix')\n",
    "for method in methods:\n",
    "    funclib.evaluate(method, X_train_uni, Y_train_uni, X_test_uni, Y_test_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e6f45-b774-40fe-868d-bbea24a0cfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076c315-90a6-4c29-848f-5608349e2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c6a10b63-dea0-41a2-b6c6-5493d07a3cf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;34m/home/shizhenkun/anaconda3/envs/jupyterlab-debugger/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m, in \u001b[0;32mrun_code\u001b[0m:\nLine \u001b[0;34m3437\u001b[0m:  exec(code_obj, \u001b[36mself\u001b[39;49;00m.user_global_ns, \u001b[36mself\u001b[39;49;00m.user_ns)\n",
      "In  \u001b[0;34m[156]\u001b[0m:\nLine \u001b[0;34m1\u001b[0m:     \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Sequential\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e76d12-d5b5-499d-a3ee-53ed1ea0f3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ec330-73dc-439e-9116-3004d590b29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c50e4-b118-481e-90b3-ffe4f265ea4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880d3c1-aae6-452e-bb5a-706daf01d140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e610d-43a0-4105-9742-a8733c9b3d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
