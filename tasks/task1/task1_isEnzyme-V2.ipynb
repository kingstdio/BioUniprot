{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task1. 预测是酶还是非酶\n",
    "\n",
    "> author: Shizhenkun   \n",
    "> email: zhenkun.shi@tib.cas.cn   \n",
    "> date: 2021-05-26  \n",
    "\n",
    "## 任务简介\n",
    "该任务通过给定蛋白序列，预测该该蛋白是酶还是非酶。本任务所使用的数据集为Sport，对数据集的数据中进行学习，然后对新给定的蛋白序列数据预测是酶还是非酶。\n",
    "\n",
    "\n",
    "## 数据统计\n",
    "- 数据源Sprot，酶 219,227 条， 非酶226,539条。\n",
    "- 将数据集中的所有数据按照时间排序，～90%作为训练集，～10%作为测试集，找到对应时间节点为2009年12月14日。\n",
    "- 以2009年12月14日为时间节点，之前的数据为训练集，之后的数据为测试集，具体数据集统计如下： \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|     Items    | 酶       |   非酶    |合计                               |\n",
    "| ------------ | --------| --------- |----------------------------------|\n",
    "| 训练集        | 198,692 | 208,391   | 407,083（407,083/453,212=89.82%)  |\n",
    "| 测试集        | 20,535  | 25,594    | 46,129 (46,129/453,212=10.18% )  |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 实验方法\n",
    "\n",
    "- 同源比对：使用训练集建立比对库，然后将测试集与之比对，取最优的比对结果，比对结果的（酶/非酶）属性当作测试集的测试结果\n",
    "- 传统机器学习方法\n",
    "- 深度学习方法\n",
    "\n",
    "\n",
    "\n",
    "## 实验结果\n",
    "\n",
    "### baselines\n",
    "\n",
    "|Methods   | Accuracy                        |             Precision           |           Recall               |F1   |\n",
    "| ---------| ------------------------------- | ------------------------------- |--------------------------------|-----|\n",
    "| 同源比对  |  0.7273298792516638(33551/46129) | 0.9637491741590785(33551/34813) |0.754687940341217(34813/46129) |      |\n",
    "| DeepEC  |  0.7685620759175356(35453/46129) | 0.5372317856709904(35453/65992) |1.43059680461315(65992/46129)  |      |\n",
    "\n",
    "\n",
    "### 机器学习 + onehot\n",
    "\n",
    "\n",
    "|baslineName| accuracy \t |precision(PPV) |\t NPV \t |\trecall |\tf1 \t |\t auroc \t |\t auprc \t |\t confusion Matrix\t\t\t\t\t\t|\n",
    "| ----------| -----------|---------------| --------- | --------|---------|-----------|---------- |------------------------------------------|\n",
    "| lr \t\t|\t0.609676 |\t0.560377 \t |\t0.680254 |0.715023 |0.628324 |\t0.661484 |\t0.568861 |\t tp: 14683 fp: 11519 fn: 5852 tn: 12450\t|\n",
    "| xg \t\t|\t0.665446 |\t0.643591 \t |\t0.682740 |0.616168 |0.629581 |\t0.742674 |\t0.684483 |\t tp: 12653 fp: 7007 fn: 7882 tn: 16962\t|\n",
    "| dt \t\t|\t0.602418 |\t0.570965 \t |\t0.628129 |0.556562 |0.563671 |\t0.599133 |\t0.522388 |\t tp: 11429 fp: 8588 fn: 9106 tn: 15381\t|\n",
    "| rf \t\t|\t0.666479 |\t0.624934 \t |\t0.710044 |0.693255 |0.657324 |\t0.745132 |\t0.689971 |\t tp: 14236 fp: 8544 fn: 6299 tn: 15425\t|\n",
    "| gbdt  \t| \t0.624079 |\t0.569351 \t |\t0.712026 |0.760604 |0.651226 |\t0.695638 |\t0.628716 |\t tp: 15619 fp: 11814 fn: 4916 tn: 12155\t|\n",
    "\n",
    "\n",
    "### 机器学习 + unirep\n",
    "\n",
    "|baslineName| accuracy \t |precision(PPV) |\t NPV \t |\trecall |\tf1 \t |\t auroc \t |\t auprc \t |\t confusion Matrix\t\t\t\t\t  |\n",
    "| ----------| -----------|---------------| --------- | --------|---------|-----------|---------- |----------------------------------------|\n",
    "|lr \t    |0.826757 \t |\t0.849132 \t |\t0.811034 |0.759484 |0.801810 |\t0.901500 |\t0.892720 |\t tp: 15596 fp: 2771 fn: 4939 tn: 21198|\n",
    "|xg \t    |0.860260\t |\t0.883725 \t |\t0.843327 |0.802776 |0.841308 |\t0.934751 |\t0.927646 |\t tp: 16485 fp: 2169 fn: 4050 tn: 21800|\n",
    "|dt \t    |0.772290 \t |\t0.767612 \t |\t0.775916 |0.726418 |0.746447 |\t0.769004 |\t0.683843 |\t tp: 14917 fp: 4516 fn: 5618 tn: 19453|\n",
    "|rf \t    |0.851070    |\t0.903031 \t |\t0.818172 |0.758705 |0.824600 |\t0.932207 |\t0.922548 |\t tp: 15580 fp: 1673 fn: 4955 tn: 22296|\n",
    "|gbdt \t\t|0.822825 \t |0.864764 \t\t |0.796054 \t |0.730217 |0.791815 |\t0.898601 |\t0.889249 |\t tp: 14995 fp: 2345 fn: 5540 tn: 21624|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的包、定义公共函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import gzip\n",
    "import re\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../../tools/\")\n",
    "import commontools\n",
    "import funclib\n",
    "from pyecharts.globals import CurrentConfig, OnlineHostType\n",
    "CurrentConfig.ONLINE_HOST = OnlineHostType.NOTEBOOK_HOST\n",
    "from pyecharts.globals import CurrentConfig, NotebookType\n",
    "CurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_LAB\n",
    "\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Bar\n",
    "from pyecharts.faker import Faker\n",
    "from pyecharts.globals import ThemeType\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_hdf('./data/train.h5',key='data')\n",
    "test = pd.read_hdf('./data/test.h5',key='data')\n",
    "head = funclib.table_head + ['f'+str(i) for i in range(1, 1901) ]\n",
    "train.columns = head\n",
    "test.columns = head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 同源比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "Write finished\n",
      "diamond makedb --in /tmp/train.fasta -d /tmp/train.dmnd\n",
      "diamond blastp -d /tmp/train.dmnd  -q  /tmp/test.fasta -o /tmp/test_fasta_results.tsv -b5 -c1 -k 1\n"
     ]
    }
   ],
   "source": [
    "res_data=funclib.getblast(train,test)\n",
    "\n",
    "#匹配查询结果\n",
    "data_match = pd.merge(test,res_data, on=['id'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 34813/34813 [15:30<00:00, 37.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total query records are: 46129\n",
      "Matched records are: 34813\n",
      "Accuracy: 0.7273298792516638(33551/46129)\n",
      "Pricision: 0.9637491741590785(33551/34813)\n",
      "Recall: 0.754687940341217(34813/46129)\n"
     ]
    }
   ],
   "source": [
    "# 添加查询结果的EC号\n",
    "resArray =[]\n",
    "for i in tqdm(range(len(res_data))):\n",
    "    mn = train[train['id']== res_data['sseqid'][i]]['isemzyme'].values\n",
    "    resArray.append(mn)\n",
    "data_match['sresults_isemzyme']=np.array(resArray) \n",
    "\n",
    "# 计算指标\n",
    "data_match['iscorrect'] = data_match[['isemzyme', 'sresults_isemzyme']].apply(lambda x: x['isemzyme'] == x['sresults_isemzyme'], axis=1) #判断EC号是否一致\n",
    "correct = sum(data_match['iscorrect'])\n",
    "find  = len(data_match)\n",
    "total = len(test)\n",
    "print('Total query records are: {0}'.format(total))\n",
    "print('Matched records are: {0}'.format(find))\n",
    "print('Accuracy: {0}({1}/{2})'.format(correct/total, correct, total))\n",
    "print('Pricision: {0}({1}/{2})'.format(correct/find, correct, find))\n",
    "print('Recall: {0}({1}/{2})'.format(find/total, find, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. 机器学习方法预测\n",
    "### 4.1 one-hot + 机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train[['id', 'isemzyme','seq', 'seqlength']].reset_index(drop=True)\n",
    "testset = test[['id', 'isemzyme','seq', 'seqlength']].reset_index(drop=True)\n",
    "\n",
    "MAX_SEQ_LENGTH = 1500 #定义序列最长的长度\n",
    "trainset.seq = trainset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))\n",
    "testset.seq = testset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = funclib.dna_onehot(trainset) #训练集编码\n",
    "f_test = funclib.dna_onehot(testset) #测试集编码\n",
    "\n",
    "train_full = pd.concat([trainset, f_train], axis=1, join='inner' ) #拼合训练集\n",
    "test_full = pd.concat([testset, f_test], axis=1, join='inner' )    #拼合测试集\n",
    "\n",
    "X_train = train_full.iloc[:,4:]\n",
    "X_test = test_full.iloc[:,4:]\n",
    "Y_train = train_full.isemzyme.astype('int')\n",
    "Y_test = test_full.isemzyme.astype('int')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t auroc \t\t auprc \t\t confusion Matrix\n",
      "lr \t\t0.599081 \t0.538479 \t\t0.681049 \t0.695447 \t0.606979 \t0.649262 \t0.540892 \t tp: 14281 fp: 12240 fn: 6254 tn: 13354\n",
      "xg \t\t0.662880 \t0.626024 \t\t0.690533 \t0.602824 \t0.614205 \t0.729195 \t0.653786 \t tp: 12379 fp: 7395 fn: 8156 tn: 18199\n",
      "dt \t\t0.601010 \t0.551674 \t\t0.640856 \t0.553689 \t0.552680 \t0.596333 \t0.504138 \t tp: 11370 fp: 9240 fn: 9165 tn: 16354\n",
      "rf \t\t0.654989 \t0.600400 \t\t0.709312 \t0.672705 \t0.634499 \t0.732298 \t0.662396 \t tp: 13814 fp: 9194 fn: 6721 tn: 16400\n",
      "gbdt \t\t0.610440 \t0.546365 \t\t0.706411 \t0.735963 \t0.627147 \t0.684524 \t0.602722 \t tp: 15113 fp: 12548 fn: 5422 tn: 13046\n"
     ]
    }
   ],
   "source": [
    "funclib.run_baseline(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Unirep + 机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,12:]\n",
    "X_test = test.iloc[:,12:]\n",
    "Y_train = train.iloc[:,2].astype('int')\n",
    "Y_test = test.iloc[:,2].astype('int')\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train).flatten()\n",
    "Y_test = np.array(Y_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baslineName \t accuracy \t precision(PPV) \t NPV \t\t recall \t f1 \t\t auroc \t\t auprc \t\t confusion Matrix\n",
      "lr \t\t0.806066 \t0.804573 \t\t0.807113 \t0.745410 \t0.773862 \t0.881648 \t0.857795 \t tp: 15307 fp: 3718 fn: 5228 tn: 21876\n",
      "xg \t\t0.838952 \t0.837158 \t\t0.840258 \t0.792355 \t0.814140 \t0.915790 \t0.896587 \t tp: 16271 fp: 3165 fn: 4264 tn: 22429\n",
      "dt \t\t0.756899 \t0.734821 \t\t0.773571 \t0.710202 \t0.722302 \t0.752284 \t0.650879 \t tp: 14584 fp: 5263 fn: 5951 tn: 20331\n",
      "rf \t\t0.832578 \t0.857677 \t\t0.816648 \t0.748040 \t0.799116 \t0.914840 \t0.893545 \t tp: 15361 fp: 2549 fn: 5174 tn: 23045\n",
      "gbdt \t\t0.803377 \t0.819520 \t\t0.793103 \t0.715997 \t0.764269 \t0.882290 \t0.856353 \t tp: 14703 fp: 3238 fn: 5832 tn: 22356\n"
     ]
    }
   ],
   "source": [
    "funclib.run_baseline(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. DeepEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "2021-06-10 15:53:37.877576: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-10 16:15:35.268850: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-10 16:15:35.359579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:81:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-06-10 16:15:35.360343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:c1:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-06-10 16:15:35.361071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:c2:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-06-10 16:15:35.361099: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-10 16:15:35.363065: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-10 16:15:35.363106: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-10 16:15:35.363841: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-10 16:15:35.364030: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-10 16:15:35.365831: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-06-10 16:15:35.366217: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-10 16:15:35.366321: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-10 16:15:35.370625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2\n",
      "2021-06-10 16:15:35.370999: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-10 16:15:35.610236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:81:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-06-10 16:15:35.610902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:c1:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-06-10 16:15:35.611536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:c2:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-06-10 16:15:35.615213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2\n",
      "2021-06-10 16:15:35.615272: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-10 16:15:36.430108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-10 16:15:36.430170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 \n",
      "2021-06-10 16:15:36.430183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N N \n",
      "2021-06-10 16:15:36.430190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N N \n",
      "2021-06-10 16:15:36.430194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   N N N \n",
      "2021-06-10 16:15:36.435048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8100 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:81:00.0, compute capability: 8.6)\n",
      "2021-06-10 16:15:36.436123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8100 MB memory) -> physical GPU (device: 1, name: GeForce RTX 3080, pci bus id: 0000:c1:00.0, compute capability: 8.6)\n",
      "2021-06-10 16:15:36.437009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 8100 MB memory) -> physical GPU (device: 2, name: GeForce RTX 3080, pci bus id: 0000:c2:00.0, compute capability: 8.6)\n",
      "2021-06-10 16:15:37.708716: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5543328000 exceeds 10% of free system memory.\n",
      "2021-06-10 16:15:39.989773: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-06-10 16:15:40.009435: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3000030000 Hz\n",
      "2021-06-10 16:15:47.493912: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-10 16:15:48.042634: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2021-06-10 16:15:48.700353: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-10 16:15:49.204095: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-10 16:15:49.229644: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.19.0 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "2021-06-10 16:16:01.924161: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5543328000 exceeds 10% of free system memory.\n",
      "2021-06-10 16:16:33.134807: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5543328000 exceeds 10% of free system memory.\n",
      "diamond v2.0.8.146 (C) Max Planck Society for the Advancement of Science\n",
      "Documentation, support and updates available at http://www.diamondsearch.org\n",
      "\n",
      "#CPU threads: 1\n",
      "Scoring parameters: (Matrix=BLOSUM62 Lambda=0.267 K=0.041 Penalties=11/1)\n",
      "Temporary directory: ./data/deepec/\n",
      "#Target sequences to report alignments for: 25\n",
      "Opening the database...  [0.012s]\n",
      "Database: /home/shizhenkun/codebase/BioUniprot/baselines/deepec/deepec/data/ref_low_seq_db.dmnd (type: Diamond database, sequences: 12624, letters: 10264058)\n",
      "Block size = 2000000000\n",
      "Opening the input file...  [0.004s]\n",
      "Opening the output file...  [0.001s]\n",
      "Loading query sequences...  [0.022s]\n",
      "Masking queries...  [0.326s]\n",
      "Building query seed set...  [0.04s]\n",
      "\u001b[1;33mThe host system is detected to have 135 GB of RAM. It is recommended to increase the block size for better performance using these parameters : -b5 -c1\n",
      "\u001b[0;39mAlgorithm: Double-indexed\n",
      "Building query histograms...  [0.179s]\n",
      "Allocating buffers...  [0s]\n",
      "Loading reference sequences...  [0.016s]\n",
      "Masking reference...  [0.411s]\n",
      "Initializing temporary storage...  [0.051s]\n",
      "Building reference histograms...  [0.222s]\n",
      "Allocating buffers...  [0s]\n",
      "Processing query block 1, reference block 1/1, shape 1/2, index chunk 1/4.\n",
      "Building reference seed array...  [0.156s]\n",
      "Building query seed array...  [0.122s]\n",
      "Computing hash join...  [0.067s]\n",
      "Building seed filter...  [0.003s]\n",
      "Searching alignments...  [0.218s]\n",
      "Processing query block 1, reference block 1/1, shape 1/2, index chunk 2/4.\n",
      "Building reference seed array...  [0.183s]\n",
      "Building query seed array...  [0.146s]\n",
      "Computing hash join...  [0.057s]\n",
      "Building seed filter...  [0.002s]\n",
      "Searching alignments...  [0.205s]\n",
      "Processing query block 1, reference block 1/1, shape 1/2, index chunk 3/4.\n",
      "Building reference seed array...  [0.208s]\n",
      "Building query seed array...  [0.156s]\n",
      "Computing hash join...  [0.057s]\n",
      "Building seed filter...  [0.002s]\n",
      "Searching alignments...  [0.169s]\n",
      "Processing query block 1, reference block 1/1, shape 1/2, index chunk 4/4.\n",
      "Building reference seed array...  [0.148s]\n",
      "Building query seed array...  [0.122s]\n",
      "Computing hash join...  [0.057s]\n",
      "Building seed filter...  [0.002s]\n",
      "Searching alignments...  [0.163s]\n",
      "Processing query block 1, reference block 1/1, shape 2/2, index chunk 1/4.\n",
      "Building reference seed array...  [0.156s]\n",
      "Building query seed array...  [0.114s]\n",
      "Computing hash join...  [0.056s]\n",
      "Building seed filter...  [0.002s]\n",
      "Searching alignments...  [0.178s]\n",
      "Processing query block 1, reference block 1/1, shape 2/2, index chunk 2/4.\n",
      "Building reference seed array...  [0.184s]\n",
      "Building query seed array...  [0.137s]\n",
      "Computing hash join...  [0.057s]\n",
      "Building seed filter...  [0.002s]\n",
      "Searching alignments...  [0.166s]\n",
      "Processing query block 1, reference block 1/1, shape 2/2, index chunk 3/4.\n",
      "Building reference seed array...  [0.199s]\n",
      "Building query seed array...  [0.156s]\n",
      "Computing hash join...  [0.057s]\n",
      "Building seed filter...  [0.002s]\n",
      "Searching alignments...  [0.16s]\n",
      "Processing query block 1, reference block 1/1, shape 2/2, index chunk 4/4.\n",
      "Building reference seed array...  [0.145s]\n",
      "Building query seed array...  [0.112s]\n",
      "Computing hash join...  [0.057s]\n",
      "Building seed filter...  [0.002s]\n",
      "Searching alignments...  [0.151s]\n",
      "Deallocating buffers...  [0.002s]\n",
      "Clearing query masking...  [0.002s]\n",
      "Computing alignments...  [9.488s]\n",
      "Deallocating reference...  [0.001s]\n",
      "Loading reference sequences...  [0s]\n",
      "Deallocating buffers...  [0.001s]\n",
      "Deallocating queries...  [0s]\n",
      "Loading query sequences...  [0s]\n",
      "Closing the input file...  [0s]\n",
      "Closing the output file...  [0.002s]\n",
      "Closing the database file...  [0s]\n",
      "Deallocating taxonomy...  [0s]\n",
      "Total time = 15.257s\n",
      "Reported 10545 pairwise alignments, 10545 HSPs.\n",
      "2120 queries aligned.\n",
      "\u001b[1;33mThe host system is detected to have 135 GB of RAM. It is recommended to increase the block size for better performance using these parameters : -b5 -c1\n",
      "\u001b[0;39mINFO: Elapsed time 00:23:22\n"
     ]
    }
   ],
   "source": [
    "funclib.table2fasta(test, './data/deepec.fasta')\n",
    "! python ../../baselines/deepec/deepec.py -i ./data/deepec.fasta -o ./data/deepec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query ID</th>\n",
       "      <th>Predicted class</th>\n",
       "      <th>DNN activity</th>\n",
       "      <th>isemzyme</th>\n",
       "      <th>isemzyme_pred</th>\n",
       "      <th>iscorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0VRF9</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C6E8M5</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3SWM0</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Query ID Predicted class  DNN activity isemzyme  isemzyme_pred  iscorrect\n",
       "0   B0VRF9          Enzyme      0.999659     True           True       True\n",
       "1   C6E8M5          Enzyme      0.999995     True           True       True\n",
       "2   Q3SWM0          Enzyme      0.999750     True           True       True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_deepec = pd.read_csv('./data/deepec/log_files/Enzyme_prediction.txt', header=0, sep='\\t')\n",
    "ec_dict = {v: k for k,v in zip(test.isemzyme, test.id )} \n",
    "res_deepec['isemzyme'] = res_deepec.apply(lambda x: ec_dict.get(x['Query ID']), axis=1)\n",
    "res_deepec['isemzyme_pred'] = res_deepec.apply(lambda x: (x['Predicted class']=='Enzyme'), axis=1)\n",
    "res_deepec['iscorrect'] = res_deepec.apply(lambda x: (x['isemzyme_pred']==x['isemzyme']), axis=1)\n",
    "res_deepec.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total query records are: 46129\n",
      "Matched records are: 65992\n",
      "Accuracy: 0.7685620759175356(35453/46129)\n",
      "Pricision: 0.5372317856709904(35453/65992)\n",
      "Recall: 1.43059680461315(65992/46129)\n"
     ]
    }
   ],
   "source": [
    "correct = sum(res_deepec['iscorrect'])\n",
    "find  = len(res_deepec)\n",
    "total = len(test)\n",
    "print('Total query records are: {0}'.format(total))\n",
    "print('Matched records are: {0}'.format(find))\n",
    "print('Accuracy: {0}({1}/{2})'.format(correct/total, correct, total))\n",
    "print('Pricision: {0}({1}/{2})'.format(correct/find, correct, find))\n",
    "print('Recall: {0}({1}/{2})'.format(find/total, find, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 集成模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
