{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ddce4b9-e814-4a6b-a347-78f8d73b3d2a",
   "metadata": {},
   "source": [
    "# Task3. 酶的EC号预测\n",
    "\n",
    "> author: Shizhenkun   \n",
    "> email: zhenkun.shi@tib.cas.cn   \n",
    "> date: 2021-06-03  \n",
    "\n",
    "## 任务简介\n",
    "该任务通过给定酶序列，预测该酶的反应类别（EC号）\n",
    "\n",
    "\n",
    "## 数据统计\n",
    "- 遵照任务1找到的时间节点对数据进行划分\n",
    "- 以2009年12月14日为时间节点，之前的数据为训练集，之后的数据为测试集，具体数据集统计如下： \n",
    "\n",
    "\n",
    "|     Items    | 单功能酶       |   多功能非酶    |合计                     |\n",
    "| ------------ | --------| --------- |----------------------------------|\n",
    "| 训练集        | 185,453 | 13,239    | 198,692（198,692/219,227=90.63%) |\n",
    "| 测试集        | 18,868  | 25,594    | 20,535 (20,535/219,227=9.37% )   |\n",
    "\n",
    "\n",
    "## 数据集构建方法\n",
    "\n",
    "* 根据蛋白注释信息与之前划定的酶与非酶数据集，将「酶」数据进行分类。\n",
    "* 有1个EC号的被定义为「单功能酶」，有多个EC号的被定义为「多功能酶」。\n",
    "\n",
    "\n",
    "## 实验结果\n",
    "\n",
    "### 同源比对\n",
    "\n",
    "|Methods   | Accuracy                        |             Precision           |           Recall               |F1   |\n",
    "| ---------| ------------------------------- | ------------------------------- |--------------------------------|-----|\n",
    "| 同源比对  |  0.6345134619461522(11972/18868) | 0.7470360663921128(11972/16026) |0.84937460250159(16026/18868)   |      |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 机器学习 + onehot\n",
    "\n",
    "\n",
    "|baslineName| accuracy \t |precision(PPV) |\t NPV \t |\trecall |\tf1 \t |\t auroc \t |\t auprc \t |\t confusion Matrix\t\t\t\t\t|\n",
    "| ------| ----------|-----------| ---------- | ----------|-----------|-----------|---------- |------------------------------------------|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 机器学习 + unirep\n",
    "\n",
    "|baslineName| accuracy \t |precision(PPV) |\t NPV \t |\trecall |\tf1 \t |\t auroc \t |\t auprc \t |\t confusion Matrix\t\t\t\t\t    |\n",
    "| ----------| -----------|---------------| --------- | --------|---------|-----------|---------- |------------------------------------------|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0846ae61",
   "metadata": {},
   "source": [
    "## 1. 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7cc57be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"../../tools/\")\n",
    "import commontools\n",
    "import funclib\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c20f23",
   "metadata": {},
   "source": [
    "## 2. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4228269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_hdf('./data/train.h5',key='data')\n",
    "test = pd.read_hdf('./data/test.h5',key='data')\n",
    "head = funclib.table_head + ['f'+str(i) for i in range(1, 1901) ]\n",
    "head = head + ['ec_label','ec_appears']\n",
    "train.columns = head\n",
    "test.columns = head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ceb1b5",
   "metadata": {},
   "source": [
    "## 3. 同源比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fd119c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "Write finished\n",
      "diamond makedb --in /tmp/train.fasta -d /tmp/train.dmnd\n",
      "diamond blastp -d /tmp/train.dmnd  -q  /tmp/test.fasta -o /tmp/test_fasta_results.tsv -b5 -c1 -k 1\n"
     ]
    }
   ],
   "source": [
    "res_data=funclib.getblast(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d2f1f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total query records are: 18868\n",
      "Matched records are: 16026\n",
      "Accuracy: 0.6345134619461522(11972/18868)\n",
      "Pricision: 0.7470360663921128(11972/16026)\n",
      "Recall: 0.84937460250159(16026/18868)\n"
     ]
    }
   ],
   "source": [
    "# 匹配查询结果\n",
    "id_map_ec = train[['id', 'ec_number']].append(test[['id', 'ec_number']],ignore_index=True)\n",
    "id_ec_dict = {v: k for v,k in zip( id_map_ec.id, id_map_ec.ec_number)} \n",
    "res_data['is_ec_match']=res_data.apply(lambda x: (id_ec_dict.get(x['id'])== id_ec_dict.get(x['sseqid'])), axis=1)\n",
    "\n",
    "# 输出比对结果\n",
    "funclib.evaluateBlast(res_data,train,test, 'ec_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290026b",
   "metadata": {},
   "source": [
    "## 4. 机器学习EC号预测\n",
    "### 4.1 onehot + 机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf769596",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train[['id', 'ec_label','seq', 'seqlength']].reset_index(drop=True)\n",
    "testset = test[['id', 'ec_label','seq', 'seqlength']].reset_index(drop=True)\n",
    "\n",
    "MAX_SEQ_LENGTH = 1000 #定义序列最长的长度\n",
    "trainset.seq = trainset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))\n",
    "testset.seq = testset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))\n",
    "\n",
    "f_train = funclib.dna_onehot(trainset) #训练集编码\n",
    "f_test = funclib.dna_onehot(testset) #测试集编码\n",
    "\n",
    "train_full = pd.concat([trainset, f_train], axis=1, join='inner' ) #拼合训练集\n",
    "test_full = pd.concat([testset, f_test], axis=1, join='inner' )    #拼合测试集\n",
    "\n",
    "X_train = np.array(train_full.iloc[:,4:])\n",
    "X_test = np.array(test_full.iloc[:,4:])\n",
    "Y_train = np.array(train_full.ec_label.astype('int'))\n",
    "Y_test = np.array(test_full.ec_label.astype('int'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea73dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "xgboost模型： XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=15,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-2, num_class=5, num_parallel_tree=None,\n",
      "              objective='multi:softmax', random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)\n",
      "[18:33:00] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgboost_clf = XGBClassifier(min_child_weight=6,max_depth=15, objective='multi:softmax',num_class=5, n_jobs=-2)\n",
    "print(\"-\" * 60)\n",
    "print(\"xgboost模型：\", xgboost_clf)\n",
    "clf = xgboost_clf.fit(X_train, Y_train)\n",
    "res = clf.predict(X_test)\n",
    "aa = pd.DataFrame()\n",
    "aa['ground_truth'] = Y_test\n",
    "aa['pred'] = res\n",
    "aa['iscorrect']= aa.apply(lambda x: x.ground_truth == x.pred, axis=1)\n",
    "aa.iscorrect.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1709e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0ca649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5432ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub= train[train.ec_appears>=100]\n",
    "test_sub= test[test.ec_appears>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21439be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train_sub[['id', 'ec_label','seq', 'seqlength']].reset_index(drop=True)\n",
    "testset = test_sub[['id', 'ec_label','seq', 'seqlength']].reset_index(drop=True)\n",
    "\n",
    "MAX_SEQ_LENGTH = 1000 #定义序列最长的长度\n",
    "trainset.seq = trainset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))\n",
    "testset.seq = testset.seq.map(lambda x : x[0:MAX_SEQ_LENGTH].ljust(MAX_SEQ_LENGTH, 'X'))\n",
    "\n",
    "f_train = funclib.dna_onehot(trainset) #训练集编码\n",
    "f_test = funclib.dna_onehot(testset) #测试集编码\n",
    "\n",
    "train_full = pd.concat([trainset, f_train], axis=1, join='inner' ) #拼合训练集\n",
    "test_full = pd.concat([testset, f_test], axis=1, join='inner' )    #拼合测试集\n",
    "\n",
    "X_train = np.array(train_full.iloc[:,4:])\n",
    "X_test = np.array(test_full.iloc[:,4:])\n",
    "Y_train = np.array(train_full.ec_label.astype('int'))\n",
    "Y_test = np.array(test_full.ec_label.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a11d4e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "xgboost模型： XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=15,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-2, num_class=5, num_parallel_tree=None,\n",
      "              objective='multi:softmax', random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shizhenkun/anaconda3/envs/py38/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:02] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1604"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_clf = XGBClassifier(min_child_weight=6,max_depth=15, objective='multi:softmax',num_class=5, n_jobs=-2)\n",
    "print(\"-\" * 60)\n",
    "print(\"xgboost模型：\", xgboost_clf)\n",
    "clf = xgboost_clf.fit(X_train, Y_train)\n",
    "res = clf.predict(X_test)\n",
    "aa = pd.DataFrame()\n",
    "aa['ground_truth'] = Y_test\n",
    "aa['pred'] = res\n",
    "aa['iscorrect']= aa.apply(lambda x: x.ground_truth == x.pred, axis=1)\n",
    "aa.iscorrect.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a5ed1a1-2cec-4823-b2d6-df3094480925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16916262391900444"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1604/len(test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "034ed9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9482"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2253b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452c00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdd1a471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed9fed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf = dtc.fit(X_train, Y_train)\n",
    "res = clf.predict(X_test)\n",
    "# print(y_test)\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8a064c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edc220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb7f542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75121ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90852a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3885d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab8bc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93212153",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-160f6dbb5b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_iris' is not defined"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "x = iris['data']\n",
    "y = iris['target']\n",
    "dtc = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "clf = dtc.fit(x_train, y_train)\n",
    "print(clf.predict(x_test))\n",
    "print(y_test)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0645bea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008888888888888889"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "160/18000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c244fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
